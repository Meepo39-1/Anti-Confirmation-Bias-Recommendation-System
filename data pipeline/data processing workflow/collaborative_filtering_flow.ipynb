{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdata_processing\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#load data\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[43mdata_processing\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_resources_from_raw_delta_logs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmin_num_interactions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m data_processing\u001b[38;5;241m.\u001b[39mload_users(min_num_interactions\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m      6\u001b[0m data_processing\u001b[38;5;241m.\u001b[39mcompute_ratings()\n",
      "File \u001b[1;32mc:\\Users\\A&A\\Desktop\\Anti Confirmation Bias Recommendation System\\data pipeline\\data processing workflow\\data_processing.py:196\u001b[0m, in \u001b[0;36mload_resources_from_raw_delta_logs\u001b[1;34m(out_file, min_num_interactions)\u001b[0m\n\u001b[0;32m    194\u001b[0m     delta_logs_file\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m    195\u001b[0m \u001b[38;5;66;03m#print(current_working_directory)          \u001b[39;00m\n\u001b[1;32m--> 196\u001b[0m \u001b[43mextract_resources_from_delta_logs_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdelta_logs_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmin_num_interactions\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\A&A\\Desktop\\Anti Confirmation Bias Recommendation System\\data pipeline\\data processing workflow\\data_processing.py:187\u001b[0m, in \u001b[0;36mload_resources_from_raw_delta_logs.<locals>.extract_resources_from_delta_logs_file\u001b[1;34m(res_file_path, delta_logs_file_path, min_num_interactions, tolerance_limit)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m delta_logs_file:\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 187\u001b[0m         \u001b[43mextract_delta_log_titles_urls_interactions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m,\u001b[49m\u001b[43mres_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtitles\u001b[49m\u001b[43m,\u001b[49m\u001b[43murls\u001b[49m\u001b[43m,\u001b[49m\u001b[43mMIN_NUM_INTERACTIONS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    188\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e: \n\u001b[0;32m    189\u001b[0m         \u001b[38;5;28mprint\u001b[39m(e)\n",
      "File \u001b[1;32mc:\\Users\\A&A\\Desktop\\Anti Confirmation Bias Recommendation System\\data pipeline\\data processing workflow\\data_processing.py:168\u001b[0m, in \u001b[0;36mload_resources_from_raw_delta_logs.<locals>.extract_delta_log_titles_urls_interactions\u001b[1;34m(line, out_file, titles, urls, min_num_interactions)\u001b[0m\n\u001b[0;32m    166\u001b[0m res_id[title] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mid\u001b[39m\n\u001b[0;32m    167\u001b[0m id_res[\u001b[38;5;28mid\u001b[39m] \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m\"\u001b[39m:title,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpos_feedback\u001b[39m\u001b[38;5;124m'\u001b[39m:pos_feedback_users,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneg_feedback\u001b[39m\u001b[38;5;124m'\u001b[39m:neg_feedback_users,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m'\u001b[39m:url}\n\u001b[1;32m--> 168\u001b[0m \u001b[43mout_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mid\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtitle\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mtitle\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpos_feedback\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mpos_feedback_users\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mneg_feedback\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mneg_feedback_users\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43murl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43murl\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    169\u001b[0m out_file\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    171\u001b[0m search_titles\u001b[38;5;241m.\u001b[39madd(title)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import data_processing\n",
    "\n",
    "#load data\n",
    "data_processing.load_resources_from_raw_delta_logs(min_num_interactions=6)\n",
    "data_processing.load_users(min_num_interactions=10)\n",
    "data_processing.compute_ratings()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error = 0.018822509641530854\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def compute_matrix_factorization():\n",
    "    import os\n",
    "    from pyspark.sql import SparkSession\n",
    "    from pyspark.sql.functions import col \n",
    "    from pyspark.ml.evaluation import RegressionEvaluator\n",
    "    from pyspark.ml.recommendation import ALS\n",
    "    from pyspark.sql import Row\n",
    "    import os\n",
    "    import sys\n",
    "\n",
    "    # os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "    # os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "\n",
    "    import findspark\n",
    "\n",
    "    findspark.init()\n",
    "\n",
    "    path = os.path.join('data processing session','extracted_ratings')\n",
    "    spark = SparkSession.builder.appName(\"Collaborative Filtering Flow\").getOrCreate()\n",
    "\n",
    "\n",
    "    lines = spark.read.text(path).rdd\n",
    "\n",
    "    parts = lines.map(lambda row: row.value.split(\" \"))\n",
    "    ratingsRDD = parts.map(lambda p: Row(userId=int(p[0]), postId=int(p[1]),\n",
    "                                        rating=float(p[2]) ))\n",
    "\n",
    "\n",
    "    ratings = spark.createDataFrame(ratingsRDD)\n",
    "    (training, test) = ratings, ratings\n",
    "    # # Build the recommendation model using ALS on the training data\n",
    "    # # Note we set cold start strategy to 'drop' to ensure we don't get NaN evaluation metrics\n",
    "    als = ALS(maxIter=5, regParam=0.01, userCol=\"userId\", itemCol=\"postId\", ratingCol=\"rating\",\n",
    "            coldStartStrategy=\"drop\")\n",
    "    model = als.fit(training)\n",
    "\n",
    "    # # Evaluate the model by computing the RMSE on the test data\n",
    "    predictions = model.transform(test)\n",
    "    evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",\n",
    "                                    predictionCol=\"prediction\")\n",
    "    rmse = evaluator.evaluate(predictions)\n",
    "    print(\"Root-mean-square error = \" + str(rmse))\n",
    "    return (ratings,model,rmse)\n",
    "\n",
    "ratingsPysparkDf,model,rmse = compute_matrix_factorization()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract resources relevant to the latent factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_baseline_posts(model,cached=True):\n",
    "    import data_processing\n",
    "    titles =[\n",
    "        \"Infidelity should not happen when divorce is possible\",\n",
    "         \"The default world lingua franca should be Spanish\",\n",
    "         \"Buying clothes or goods from factories in the developing world is moral, eve...\",\n",
    "         \"The legal owner of a firearm should be responsible for the weapon and anythi...\",\n",
    "         \"Airport security screenings do very little to stop deliberate terrorism such as the attacks of 9/11. They are a show put on to make passengers think something is being done.\",\n",
    "         \"Luxury watches are useless in the practical sense\",\n",
    "         \"The concept of an omniscient (*) and capable creator is not compatible with ...\",\n",
    "         \"If whatever makes your character different (sexual identity/disability etc) ...\",\n",
    "         \"Cutlery should be placed at the end of a buffet line\",\n",
    "         \"If an animal has a big enough population, hunting of it should be allowed\"\n",
    "]\n",
    "    \n",
    "    if cached:\n",
    "        baseline_posts = []\n",
    "        for title in titles:\n",
    "            #print(title)\n",
    "            id = data_processing.res_id[title]\n",
    "            #print(id)\n",
    "            baseline_posts.append(data_processing.get_resource_info(id))\n",
    "        return baseline_posts\n",
    "    else:    \n",
    "        '''After advisor approval, these posts shall be hardcoded '''\n",
    "\n",
    "        from pyspark.sql.functions import expr\n",
    "\n",
    "        # Extract item factors\n",
    "        item_factors = model.itemFactors\n",
    "\n",
    "        # Find the top 5 highest scores for each latent factor\n",
    "        num_factors = model.rank  # Number of latent factors\n",
    "        top_scores_per_factor = []\n",
    "\n",
    "        for i in range(num_factors):\n",
    "            factor_col = expr(f\"features[{i}]\")\n",
    "            top_rows = (item_factors\n",
    "                        .select(\"id\", factor_col.alias(\"factor\"))\n",
    "                        .orderBy(\"factor\", ascending=False)\n",
    "                        .limit(10)\n",
    "                        .collect())\n",
    "            top_scores_per_factor.append((i, [(row.id, row.factor) for row in top_rows]))\n",
    "\n",
    "        #for the final version, the resources will be predefined, to ensure that the reddit posts are not deprecated\n",
    "        baseline_posts = []\n",
    "        for factor, top_scores in top_scores_per_factor:\n",
    "            for rank, (post_id, factor_score) in enumerate(top_scores, start=1):\n",
    "                if rank ==1:\n",
    "                    baseline_posts.append({'id':post_id,'score':factor_score,'content':data_processing.id_res[post_id]})\n",
    "                print(f'title:{data_processing.id_res[post_id][\"title\"]},url:{data_processing.id_res[post_id][\"url\"]},factor {factor},score:{factor_score}')\n",
    "            print(\"-\"*100)\n",
    "        return baseline_posts\n",
    "\n",
    "baseline_posts = extract_baseline_posts(model,cached=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "344"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles =[\"Infidelity should not happen when divorce is possible\"]\n",
    "data_processing.get_resource_id(\"The default world lingua franca should be Spanish\")\n",
    "data_processing.get_resource_id(\"Buying clothes or goods from factories in the developing world is moral, eve...\")\n",
    "data_processing.get_resource_id(\"The legal owner of a firearm should be responsible for the weapon and anythi...\")\n",
    "data_processing.get_resource_id(\"Airport security screenings do very little to stop deliberate terrorism such as the attacks of 9/11. They are a show put on to make passengers think something is being done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'Infidelity should not happen when divorce is possible', 'pos_feedback': ['Nitrousoxide72', 'RedditExplorer89'], 'neg_feedback': ['ripcelinedionhusband', 'Melodic_Echidna', 'joopface', 'dublea', 'ripcelinedionhusband', 'WelfareBear', 'JimboMan1234', '', 'muyamable', 'Nephisimian', 'USoverthem'], 'url': 'https://www.reddit.com//r/changemyview/comments/imh6iw/cmv_infidelity_should_not_happen_when_divorce_is/'}\n"
     ]
    }
   ],
   "source": [
    "print(baseline_posts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 [{'title': 'Infidelity should not happen when divorce is possible', 'pos_feedback': ['Nitrousoxide72', 'RedditExplorer89'], 'neg_feedback': ['ripcelinedionhusband', 'Melodic_Echidna', 'joopface', 'dublea', 'ripcelinedionhusband', 'WelfareBear', 'JimboMan1234', '', 'muyamable', 'Nephisimian', 'USoverthem'], 'url': 'https://www.reddit.com//r/changemyview/comments/imh6iw/cmv_infidelity_should_not_happen_when_divorce_is/'}, {'title': 'The default world lingua franca should be Spanish', 'pos_feedback': ['NicholasLeo', 'BrotherItsInTheDrum'], 'neg_feedback': ['Igor_Furman', 'muyamable', '', 'MontiBurns', '', 'parentheticalobject'], 'url': 'https://www.reddit.com//r/changemyview/comments/hf49v5/cmv_the_default_world_lingua_franca_should_be/'}, {'title': 'Buying clothes or goods from factories in the developing world is moral, eve...', 'pos_feedback': ['mr-logician', 'thedobya'], 'neg_feedback': ['AnythingApplied', 'AnythingApplied', 'MercurianAspirations', 'StellaAthena'], 'url': 'https://www.reddit.com//r/changemyview/comments/dwebfc/cmv_buying_clothes_or_goods_from_factories_in_the/'}, {'title': 'The legal owner of a firearm should be responsible for the weapon and anythi...', 'pos_feedback': ['BoredRedhead'], 'neg_feedback': ['Missing_Links', 'Fanfic_Galore', 'BoyMeetsTheWorld', 'MechanicalEngineEar', 'Servant-Ruler', 'Lilah_R', 'VoodooManchester', 'DBDude', 'NastyNNaughty69', '', '600062'], 'url': 'https://www.reddit.com//r/changemyview/comments/i4f917/cmv_the_legal_owner_of_a_firearm_should_be/'}, {'title': 'Airport security screenings do very little to stop deliberate terrorism such as the attacks of 9/11. They are a show put on to make passengers think something is being done.', 'pos_feedback': ['TheloniusMusk', 'florencenightinjale'], 'neg_feedback': ['hacksoncode', 'MyUsernameIsJudge', '', 'Ansuz07', 'thisisnotariot', '', 'apparentlyapparent'], 'url': 'https://www.reddit.com/r/changemyview/comments/8a9r3h/cmv_airport_security_screenings_do_very_little_to/'}, {'title': 'Luxury watches are useless in the practical sense', 'pos_feedback': ['Crayshack', 'avatarlegend12345'], 'neg_feedback': ['KDY_ISD', 'KDY_ISD', 'HallucinatoryWalnut', 'a_sack_of_hamsters'], 'url': 'https://www.reddit.com//r/changemyview/comments/bvupnz/cmv_luxury_watches_are_useless_in_the_practical/'}, {'title': 'The concept of an omniscient (*) and capable creator is not compatible with ...', 'pos_feedback': ['Salty_Dornishman', 'PivotPsycho'], 'neg_feedback': ['badass_panda', 'JoZeHgS', 'wajubop', 'ButtonholePhotophile', 'MizunoGolfer15-20', 'NicholasLeo'], 'url': 'https://www.reddit.com//r/changemyview/comments/lbqam1/cmv_the_concept_of_an_omniscient_and_capable/'}, {'title': 'If whatever makes your character different (sexual identity/disability etc) ...', 'pos_feedback': ['GnosticGnome', 'doriangraiy'], 'neg_feedback': ['th3empirial', 'BeatriceBernardo', 'HazelGhost', 'adhd_energy_'], 'url': 'https://www.reddit.com//r/changemyview/comments/mu84wm/cmv_if_whatever_makes_your_character_different/'}, {'title': 'Cutlery should be placed at the end of a buffet line', 'pos_feedback': ['zfreakazoidz', 'Herbie_Fully_Loaded'], 'neg_feedback': ['ralph-j', 'dublea', '', 'ThinkingAboutJulia', 'erection_detection_', 'pawnman99', 'badass_panda'], 'url': 'https://www.reddit.com//r/changemyview/comments/n6y914/cmv_cutlery_should_be_placed_at_the_end_of_a/'}, {'title': 'If an animal has a big enough population, hunting of it should be allowed', 'pos_feedback': ['overhardeggs'], 'neg_feedback': ['GoblinRaiders', 'NowImAllSet', 'destro23', 'destro23', 'wantingtodobetter', 'drschwartz', '', 'hacksoncode'], 'url': 'https://www.reddit.com//r/changemyview/comments/w9hy6t/cmv_if_an_animal_has_a_big_enough_population/'}]\n"
     ]
    }
   ],
   "source": [
    "print(len(baseline_posts),baseline_posts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect data for cold start problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'baseline_posts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 27\u001b[0m\n\u001b[0;32m     23\u001b[0m             baseline_results\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m:baseline_post[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m],\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfactor_score\u001b[39m\u001b[38;5;124m'\u001b[39m:baseline_post[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m'\u001b[39m],\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_score\u001b[39m\u001b[38;5;124m'\u001b[39m:baseline_score})\n\u001b[0;32m     24\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (baseline_results,name)\n\u001b[1;32m---> 27\u001b[0m baseline_results,name \u001b[38;5;241m=\u001b[39m init_cold_start(\u001b[43mbaseline_posts\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'baseline_posts' is not defined"
     ]
    }
   ],
   "source": [
    "def init_cold_start(baseline_posts,cached=True):\n",
    "\n",
    "    import data_processing\n",
    "\n",
    "    name = input(\"Please write your name:\")\n",
    "    description = \"Dummy description of the task\"\n",
    "\n",
    "    baseline_results =[]\n",
    "\n",
    "    if cached:\n",
    "        for res in baseline_posts:\n",
    "            print(f'Title:{res[\"title\"]}')\n",
    "            print(f'url: {res[\"url\"]}')\n",
    "            baseline_score = float(input('How much did this post make you see things trough a new perspective?:'))\n",
    "            baseline_results.append({'id':data_processing.res_id[res['title']],'user_score':baseline_score})\n",
    "        return (baseline_results,name)\n",
    "    else:\n",
    "        for baseline_post in baseline_posts:\n",
    "            res = baseline_post[\"content\"]\n",
    "            print(f'Title:{res[\"title\"]}')\n",
    "            print(f'url: {res[\"url\"]}')\n",
    "            baseline_score = float(input('How much did this post make you see things trough a new perspective?:'))\n",
    "            baseline_results.append({'id':baseline_post['id'],'factor_score':baseline_post['score'],'user_score':baseline_score})\n",
    "        return (baseline_results,name)\n",
    "\n",
    "\n",
    "baseline_results,name = init_cold_start(baseline_posts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the model with the new user's data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "295\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.path.join(\"data processing session\",\"extracted_ratings\")\n",
    "def add_new_user_ratings(baseline_results):\n",
    "    ratings_path_file = r'C:\\Users\\A&A\\Downloads\\Date Personale Laptop Nagarro\\Proiect Licenta\\data pipeline\\data processing workflow\\data processing session\\extracted_ratings'\n",
    "\n",
    "    ratings_file = open(ratings_path_file,'r')\n",
    "\n",
    "\n",
    "    for line in ratings_file:\n",
    "        last_line = line\n",
    "    last_line = last_line.split(\" \")\n",
    "    new_user_id = int(last_line[0]) + 1\n",
    "    print(new_user_id)\n",
    "    ratings_file.close()\n",
    "    ratings_file = open(ratings_path_file,'a')\n",
    "\n",
    "    for result in baseline_results:\n",
    "        #ratings_file.write()\n",
    "        res_id = result['id']\n",
    "        score = result['user_score']\n",
    "        ratings_file.write(f'{new_user_id} {res_id} {score}\\n')\n",
    "        #print(f'{new_user_id} {res_id} {score}\\n')\n",
    "    ratings_file.close()\n",
    "    return new_user_id\n",
    "user_id = add_new_user_ratings(baseline_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error = 0.018861102460057386\n"
     ]
    }
   ],
   "source": [
    "def compute_matrix_factorization():\n",
    "    from pyspark.sql import SparkSession\n",
    "    from pyspark.sql.functions import col \n",
    "    from pyspark.ml.evaluation import RegressionEvaluator\n",
    "    from pyspark.ml.recommendation import ALS\n",
    "    from pyspark.sql import Row\n",
    "    import os\n",
    "    import sys\n",
    "\n",
    "    # os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "    # os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "\n",
    "    import data_processing\n",
    "    import findspark\n",
    "\n",
    "    findspark.init()\n",
    "\n",
    "    path = r'C:\\Users\\A&A\\Downloads\\Date Personale Laptop Nagarro\\Proiect Licenta\\data pipeline\\data processing workflow\\data processing session\\extracted_ratings'\n",
    "\n",
    "    spark = SparkSession.builder.appName(\"Collaborative Filtering Flow\").getOrCreate()\n",
    "\n",
    "\n",
    "    lines = spark.read.text(path).rdd\n",
    "\n",
    "    parts = lines.map(lambda row: row.value.split(\" \"))\n",
    "    ratingsRDD = parts.map(lambda p: Row(userId=int(p[0]), postId=int(p[1]),\n",
    "                                        rating=float(p[2]) ))\n",
    "\n",
    "\n",
    "    ratings = spark.createDataFrame(ratingsRDD)\n",
    "    (training, test) = ratings, ratings\n",
    "    # # Build the recommendation model using ALS on the training data\n",
    "    # # Note we set cold start strategy to 'drop' to ensure we don't get NaN evaluation metrics\n",
    "    als = ALS(maxIter=5, regParam=0.01, userCol=\"userId\", itemCol=\"postId\", ratingCol=\"rating\",\n",
    "            coldStartStrategy=\"drop\")\n",
    "    model = als.fit(training)\n",
    "\n",
    "    # # Evaluate the model by computing the RMSE on the test data\n",
    "    predictions = model.transform(test)\n",
    "    evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",\n",
    "                                    predictionCol=\"prediction\")\n",
    "    rmse = evaluator.evaluate(predictions)\n",
    "    print(\"Root-mean-square error = \" + str(rmse))\n",
    "    return (ratings,model,rmse)\n",
    "\n",
    "ratingsPysparkDf,model,rmse = compute_matrix_factorization()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make recommendations for the new user based on matrix factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract ids of already rated posts by user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_posts_already_rated(ratings,user_id = 294):\n",
    "    from pyspark.sql.functions import col \n",
    "    user_ratings = ratings.filter(col(\"userId\") == 294).select(\"postId\").distinct()\n",
    "    posts_rated_by_user = set()\n",
    "\n",
    "    for post_id in user_ratings.toPandas().values:\n",
    "        posts_rated_by_user.add(post_id[0])\n",
    "\n",
    "    #print(posts_rated_by_user)\n",
    "    return posts_rated_by_user\n",
    "current_user_already_rated_posts = extract_posts_already_rated(ratingsPysparkDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_recommendations = model.recommendForAllUsers(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------------------------------------------------------+\n",
      "|userId|recommendations                                          |\n",
      "+------+---------------------------------------------------------+\n",
      "|294   |[{1972, 1.3016436}, {1279, 1.1852648}, {2322, 1.0094897}]|\n",
      "+------+---------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#This posts have already been rated by the user\n",
    "\n",
    "user_recommendations.filter(user_recommendations.userId==294).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'post_id': 1190, 'prediction': 0.7996417880058289}, {'post_id': 268, 'prediction': 0.7205122709274292}, {'post_id': 2570, 'prediction': 0.6130921244621277}, {'post_id': 3040, 'prediction': 0.6093191504478455}, {'post_id': 2992, 'prediction': 0.5738112330436707}, {'post_id': 47, 'prediction': 0.5597562193870544}, {'post_id': 2904, 'prediction': 0.5365568399429321}, {'post_id': 3148, 'prediction': 0.5309612154960632}, {'post_id': 2915, 'prediction': 0.5214865207672119}, {'post_id': 946, 'prediction': 0.5204827189445496}, {'post_id': 607, 'prediction': 0.52031010389328}, {'post_id': 1942, 'prediction': 0.4960876703262329}, {'post_id': 138, 'prediction': 0.4893319010734558}, {'post_id': 1152, 'prediction': 0.48891910910606384}, {'post_id': 2346, 'prediction': 0.477201908826828}]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col,lit\n",
    "\n",
    "def generate_matrix_factorization_recs(ratingsPysparkDf,user_id = 294,number_recs=15,similar=True):\n",
    "    \n",
    "    # Generate recommendations for a specific user\n",
    "    user_ratings = ratingsPysparkDf.filter(col(\"userId\") == user_id).select(\"postId\").distinct()\n",
    "    #user_ratings.show()\n",
    "    all_posts = ratingsPysparkDf.select(\"postId\").distinct()\n",
    "    posts_not_rated_by_user = all_posts.join(user_ratings, on=\"postId\", how=\"left_anti\")\n",
    "\n",
    "    #posts_not_rated_by_user.show()\n",
    "\n",
    "    # Recommend top number_recs posts\n",
    "    posts_not_rated_by_user = posts_not_rated_by_user.withColumn(\"userId\", lit(user_id))\n",
    "    recommendations = model.transform(posts_not_rated_by_user)\n",
    "    if similar:\n",
    "        top_recommendations = recommendations.orderBy(col(\"prediction\").desc()).select(\"postId\", \"prediction\").limit(number_recs)\n",
    "    else:\n",
    "        top_recommendations = recommendations.orderBy(col(\"prediction\")).select(\"postId\", \"prediction\").limit(number_recs)\n",
    "\n",
    "    #top_recommendations.show()\n",
    "\n",
    "\n",
    "    #extract them in a list\n",
    "    postIds = [p[0] for p in top_recommendations.select(\"postId\").toPandas().values.tolist()]\n",
    "    predictions = [p[0] for p in top_recommendations.select(\"prediction\").toPandas().values.tolist()]\n",
    "\n",
    "    #print(postIds)\n",
    "    #print(predictions)\n",
    "\n",
    "    matrix_factorization_predictions = []\n",
    "    for index in range(len(postIds)):\n",
    "        matrix_factorization_predictions.append({'post_id':postIds[index],'prediction':predictions[index]})\n",
    "    print(matrix_factorization_predictions)\n",
    "    return matrix_factorization_predictions\n",
    "\n",
    "matrix_factorization_predictions = generate_matrix_factorization_recs(ratingsPysparkDf,user_id = 294,similar=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#after rating\n",
    "# for rec in matrix_factorization_predictions:\n",
    "#     current_user_already_rated_posts.add(rec['post_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make recommendations for the new user based on similar and opposite users\n",
    "\n",
    "### Make recommendations based on similar users\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create similarity matrix of users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          2         3         4         5         6         7         8    \\\n",
      "2    1.000000  0.426558 -0.353396 -0.517619  0.293009 -0.233070 -0.428046   \n",
      "3    0.426558  1.000000 -0.437803 -0.665493  0.367526  0.224347  0.009407   \n",
      "4   -0.353396 -0.437803  1.000000 -0.002396  0.264755  0.524021  0.389853   \n",
      "5   -0.517619 -0.665493 -0.002396  1.000000 -0.637277 -0.609434  0.055064   \n",
      "6    0.293009  0.367526  0.264755 -0.637277  1.000000  0.390253  0.217179   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "291  0.215823  0.287657  0.012634 -0.101011 -0.006236 -0.088646  0.183040   \n",
      "292 -0.015122  0.421971 -0.176516 -0.219887  0.561426  0.066851  0.429446   \n",
      "293  0.131947  0.273390 -0.558932 -0.109349 -0.180771 -0.269134  0.035844   \n",
      "294 -0.200416  0.005570 -0.460710  0.399972 -0.267628 -0.225177  0.157379   \n",
      "295 -0.200416  0.005570 -0.460710  0.399972 -0.267628 -0.225177  0.157379   \n",
      "\n",
      "          9         10        11   ...       286       287       288  \\\n",
      "2    0.066469 -0.055108 -0.165402  ... -0.487229  0.074994  0.013275   \n",
      "3    0.234440  0.542786 -0.094065  ...  0.234296  0.232424  0.012880   \n",
      "4   -0.342784 -0.001534  0.234508  ...  0.267889 -0.385427  0.437017   \n",
      "5    0.260512 -0.284206  0.152065  ...  0.081621  0.036391  0.053495   \n",
      "6   -0.074098 -0.229976 -0.077290  ... -0.091234 -0.011100  0.147621   \n",
      "..        ...       ...       ...  ...       ...       ...       ...   \n",
      "291  0.245927  0.249628 -0.215148  ...  0.152877  0.057981  0.311226   \n",
      "292  0.317531 -0.204117 -0.289121  ...  0.077075  0.045217 -0.147696   \n",
      "293  0.446712  0.320752 -0.155879  ... -0.168998  0.393578 -0.156589   \n",
      "294  0.144787 -0.300871  0.058380  ...  0.381570  0.381771 -0.255698   \n",
      "295  0.144787 -0.300871  0.058380  ...  0.381570  0.381771 -0.255698   \n",
      "\n",
      "          289       290       291       292       293       294       295  \n",
      "2    0.025671 -0.300743  0.215823 -0.015122  0.131947 -0.200416 -0.200416  \n",
      "3   -0.092346 -0.402807  0.287657  0.421971  0.273390  0.005570  0.005570  \n",
      "4    0.229847 -0.139850  0.012634 -0.176516 -0.558932 -0.460710 -0.460710  \n",
      "5   -0.267723  0.355299 -0.101011 -0.219887 -0.109349  0.399972  0.399972  \n",
      "6    0.449162 -0.085486 -0.006236  0.561426 -0.180771 -0.267628 -0.267628  \n",
      "..        ...       ...       ...       ...       ...       ...       ...  \n",
      "291 -0.133359 -0.037572  1.000000 -0.222330 -0.240399 -0.007039 -0.007039  \n",
      "292  0.086985 -0.004045 -0.222330  1.000000  0.023588  0.144685  0.144685  \n",
      "293  0.468895  0.398350 -0.240399  0.023588  1.000000  0.102831  0.102831  \n",
      "294 -0.258849  0.048424 -0.007039  0.144685  0.102831  1.000000  1.000000  \n",
      "295 -0.258849  0.048424 -0.007039  0.144685  0.102831  1.000000  1.000000  \n",
      "\n",
      "[294 rows x 294 columns]\n"
     ]
    }
   ],
   "source": [
    "def compute_user_similarity_matrix(model):\n",
    "\n",
    "    from pyspark.sql import SparkSession\n",
    "    from pyspark.ml.recommendation import ALS\n",
    "    from pyspark.sql import Row\n",
    "    import pandas as pd\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "    # Extract user factors\n",
    "    user_factors = model.userFactors.orderBy('id')\n",
    "\n",
    "    # Convert to Pandas DataFrame\n",
    "    user_factors_pd = user_factors.toPandas()\n",
    "\n",
    "    # Create a matrix of user factors\n",
    "    user_ids = user_factors_pd['id'].values\n",
    "    user_features = pd.DataFrame(user_factors_pd['features'].tolist(), index=user_ids)\n",
    "\n",
    "    # Compute cosine similarity\n",
    "    similarity_matrix = cosine_similarity(user_features)\n",
    "\n",
    "    # Convert the similarity matrix to a DataFrame for easier interpretation\n",
    "    user_similarity_df = pd.DataFrame(similarity_matrix, index=user_ids, columns=user_ids)\n",
    "\n",
    "    print(user_similarity_df)\n",
    "    return user_similarity_df\n",
    "\n",
    "user_similarity_df = compute_user_similarity_matrix(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example how to access the similarity between user with itself for  id 2 \n",
    "user_similarity_df.iloc[2][4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000000000000002"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_similarity_df.iloc[292][294]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract similar and opposite users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar users of user with id: 294\n",
      "user id: 37,similarity score: 0.7810509035373925\n",
      "user id: 97,similarity score: 0.7860258314912422\n",
      "user id: 294,similarity score: 1.0000000000000002\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Opposite users of user with id: 294\n",
      "user id: 44,similarity score: -0.778018459774237\n",
      "user id: 242,similarity score: -0.759221556823808\n",
      "user id: 226,similarity score: -0.7421612527584794\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "[(294, 1.0000000000000002), (97, 0.7860258314912422), (37, 0.7810509035373925)]\n",
      "[(44, -0.778018459774237), (242, -0.759221556823808), (226, -0.7421612527584794)]\n"
     ]
    }
   ],
   "source": [
    "def extract_similar_and_opposite_users(user_similarity_df,interogated_user_id=294):\n",
    "    import numpy as np\n",
    "\n",
    "    #Note1: if you want to check if user ids are good, \n",
    "    #replace [-4:-1] with [-4:] and see if last user has a similarity score of aprox 1\n",
    "\n",
    "    #Note2: -2 and +2 comes from the fact that we use numpy methods for a pandas dataframe, \n",
    "    # dataframe row index starts from 0; column index from 2\n",
    "\n",
    "    user_similarity_scores_df =user_similarity_df.iloc[interogated_user_id-2]\n",
    "    similar_users = []\n",
    "\n",
    "    print(f'Similar users of user with id: {interogated_user_id}')\n",
    "\n",
    "    for id in np.argsort(user_similarity_scores_df)[-4:-1]:\n",
    "        user_id = id+2 #colum indexes start from 2 because lowest user_id value is 2\n",
    "        similarity_score = user_similarity_scores_df[user_id]\n",
    "\n",
    "        similar_users.append((user_id,similarity_score))\n",
    "        try:\n",
    "            print(f'user id: {user_id},similarity score: {similarity_score}')\n",
    "        except:\n",
    "            print(f'index error is {user_id} ')\n",
    "    \n",
    "    #reverse the list so that most similar user recs come first\n",
    "    similar_users.reverse()\n",
    "\n",
    "    print('-'*100)\n",
    "\n",
    "    opposite_users = []\n",
    "\n",
    "    print(f'Opposite users of user with id: {interogated_user_id}')\n",
    "    for id in np.argsort(user_similarity_scores_df)[:3]:\n",
    "        user_id = id+2\n",
    "        similarity_score = user_similarity_scores_df[user_id]\n",
    "        try:\n",
    "        \n",
    "            opposite_users.append((user_id,similarity_score))\n",
    "            print(f'user id: {user_id},similarity score: {similarity_score}')\n",
    "        except:\n",
    "            print(f'index error is {user_id} ')\n",
    "    print('-'*200)\n",
    "    print(similar_users)\n",
    "    print(opposite_users)\n",
    "\n",
    "    return (similar_users,opposite_users)\n",
    "\n",
    "similar_users,opposite_users = extract_similar_and_opposite_users(user_similarity_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract and filter recommendations based on similar and opposite users "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar users flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id = 294\n",
      "similarity_score =1.0000000000000002\n",
      "[{'post_id': 1190, 'prediction': 0.7996417880058289}, {'post_id': 268, 'prediction': 0.7205122709274292}, {'post_id': 2570, 'prediction': 0.6130921244621277}, {'post_id': 3040, 'prediction': 0.6093191504478455}, {'post_id': 2992, 'prediction': 0.5738112330436707}, {'post_id': 47, 'prediction': 0.5597562193870544}, {'post_id': 2904, 'prediction': 0.5365568399429321}, {'post_id': 3148, 'prediction': 0.5309612154960632}, {'post_id': 2915, 'prediction': 0.5214865207672119}, {'post_id': 946, 'prediction': 0.5204827189445496}, {'post_id': 607, 'prediction': 0.52031010389328}, {'post_id': 1942, 'prediction': 0.4960876703262329}, {'post_id': 138, 'prediction': 0.4893319010734558}, {'post_id': 1152, 'prediction': 0.48891910910606384}, {'post_id': 2346, 'prediction': 0.477201908826828}, {'post_id': 1222, 'prediction': 0.4736446440219879}, {'post_id': 72, 'prediction': 0.466156542301178}, {'post_id': 1700, 'prediction': 0.4648670554161072}, {'post_id': 3076, 'prediction': 0.46226999163627625}, {'post_id': 766, 'prediction': 0.4574050307273865}, {'post_id': 2756, 'prediction': 0.4438568651676178}, {'post_id': 3618, 'prediction': 0.4437324106693268}, {'post_id': 2349, 'prediction': 0.4433387815952301}, {'post_id': 2143, 'prediction': 0.4433387815952301}, {'post_id': 93, 'prediction': 0.4424279034137726}, {'post_id': 262, 'prediction': 0.4400613009929657}, {'post_id': 2236, 'prediction': 0.4246232211589813}, {'post_id': 872, 'prediction': 0.42374157905578613}, {'post_id': 2925, 'prediction': 0.4186697006225586}, {'post_id': 1764, 'prediction': 0.4178774058818817}]\n",
      "user_id = 97\n",
      "similarity_score =0.7860258314912422\n",
      "[{'post_id': 1791, 'prediction': 1.237240195274353}, {'post_id': 2322, 'prediction': 0.9611183404922485}, {'post_id': 1909, 'prediction': 0.9425730109214783}, {'post_id': 1088, 'prediction': 0.7912934422492981}, {'post_id': 344, 'prediction': 0.7576056122779846}, {'post_id': 3102, 'prediction': 0.7437902688980103}, {'post_id': 3618, 'prediction': 0.7080808281898499}, {'post_id': 1190, 'prediction': 0.6986818313598633}, {'post_id': 2596, 'prediction': 0.6839979887008667}, {'post_id': 47, 'prediction': 0.6777585744857788}, {'post_id': 2427, 'prediction': 0.6724300980567932}, {'post_id': 1320, 'prediction': 0.6098718643188477}, {'post_id': 2006, 'prediction': 0.604168713092804}, {'post_id': 946, 'prediction': 0.5946764945983887}, {'post_id': 1194, 'prediction': 0.5906091332435608}, {'post_id': 2349, 'prediction': 0.5796627402305603}, {'post_id': 2143, 'prediction': 0.5796627402305603}, {'post_id': 2493, 'prediction': 0.5719465017318726}, {'post_id': 2992, 'prediction': 0.5714637637138367}, {'post_id': 3148, 'prediction': 0.5592288970947266}, {'post_id': 2346, 'prediction': 0.5446988940238953}, {'post_id': 2301, 'prediction': 0.5431333780288696}, {'post_id': 756, 'prediction': 0.5409673452377319}, {'post_id': 1971, 'prediction': 0.5373449325561523}, {'post_id': 135, 'prediction': 0.5354360342025757}, {'post_id': 138, 'prediction': 0.5260232090950012}, {'post_id': 2570, 'prediction': 0.520113468170166}, {'post_id': 2025, 'prediction': 0.5152558088302612}, {'post_id': 523, 'prediction': 0.5148851275444031}, {'post_id': 1402, 'prediction': 0.5103158354759216}]\n",
      "user_id = 37\n",
      "similarity_score =0.7810509035373925\n",
      "[{'post_id': 1971, 'prediction': 1.4019235372543335}, {'post_id': 2493, 'prediction': 1.1462939977645874}, {'post_id': 1320, 'prediction': 1.117098331451416}, {'post_id': 1909, 'prediction': 1.064024806022644}, {'post_id': 3102, 'prediction': 1.0106086730957031}, {'post_id': 2427, 'prediction': 0.912360668182373}, {'post_id': 1190, 'prediction': 0.8984132409095764}, {'post_id': 2322, 'prediction': 0.886572539806366}, {'post_id': 2058, 'prediction': 0.8589051365852356}, {'post_id': 344, 'prediction': 0.7815649509429932}, {'post_id': 1088, 'prediction': 0.7804531455039978}, {'post_id': 268, 'prediction': 0.737381100654602}, {'post_id': 1791, 'prediction': 0.7347620129585266}, {'post_id': 2459, 'prediction': 0.6865125894546509}, {'post_id': 403, 'prediction': 0.6802314519882202}, {'post_id': 2570, 'prediction': 0.6488656997680664}, {'post_id': 908, 'prediction': 0.6320192813873291}, {'post_id': 2236, 'prediction': 0.6268302202224731}, {'post_id': 3610, 'prediction': 0.5973417162895203}, {'post_id': 1258, 'prediction': 0.5952428579330444}, {'post_id': 3137, 'prediction': 0.5800818800926208}, {'post_id': 113, 'prediction': 0.577018141746521}, {'post_id': 1535, 'prediction': 0.577018141746521}, {'post_id': 2884, 'prediction': 0.5736508369445801}, {'post_id': 61, 'prediction': 0.5662785768508911}, {'post_id': 2572, 'prediction': 0.5647580623626709}, {'post_id': 244, 'prediction': 0.5459015369415283}, {'post_id': 2073, 'prediction': 0.5390926003456116}, {'post_id': 2129, 'prediction': 0.5361955165863037}, {'post_id': 455, 'prediction': 0.5270192623138428}]\n"
     ]
    }
   ],
   "source": [
    "def generate_sim_recs(ratings_file, baseline_users,current_user_already_rated_posts,num_recs = 30,similar=True):\n",
    "    num_users = len(baseline_users)\n",
    "    #print(num_users)\n",
    "    for index in range(num_users):\n",
    "        sim_user_id,similarity_score = baseline_users[index]\n",
    "\n",
    "        print(f'user_id = {sim_user_id}')\n",
    "        print(f'similarity_score ={similarity_score}')\n",
    "\n",
    "        sim_user_recs = generate_matrix_factorization_recs(ratings_file,user_id=sim_user_id,number_recs=num_recs,similar=similar)\n",
    "        current_user_recs = []\n",
    "        for sim_user_rec_struct in sim_user_recs:\n",
    "\n",
    "            if sim_user_rec_struct['post_id'] in current_user_already_rated_posts:\n",
    "                #print('found already rated post')\n",
    "                continue\n",
    "            else:\n",
    "                current_user_rec = {'post_id':sim_user_rec_struct['post_id'],\n",
    "                                    'prediction':sim_user_rec_struct['prediction'] * similarity_score,\n",
    "                                    'baseline_user_id':sim_user_id,\n",
    "                                    'similarity_score': similarity_score,\n",
    "                                    'baseline_user_prediction':sim_user_rec_struct['prediction'] }\n",
    "\n",
    "                #print(f'current user recommendation :{current_user_rec}')\n",
    "\n",
    "                current_user_recs.append(current_user_rec)\n",
    "    return current_user_recs\n",
    "similar_users_recs = generate_sim_recs(ratings_file=ratingsPysparkDf,baseline_users=similar_users,current_user_already_rated_posts=current_user_already_rated_posts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Opposite users flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id = 44\n",
      "similarity_score =-0.778018459774237\n",
      "[{'post_id': 2427, 'prediction': -1.3995832204818726}, {'post_id': 1320, 'prediction': -1.2892322540283203}, {'post_id': 1909, 'prediction': -1.2672719955444336}, {'post_id': 344, 'prediction': -1.1839497089385986}, {'post_id': 1971, 'prediction': -1.1302331686019897}, {'post_id': 2493, 'prediction': -1.1251966953277588}, {'post_id': 268, 'prediction': -1.0672991275787354}, {'post_id': 3040, 'prediction': -1.0038970708847046}, {'post_id': 1088, 'prediction': -0.9969940781593323}, {'post_id': 2322, 'prediction': -0.8950653076171875}, {'post_id': 2904, 'prediction': -0.8632669448852539}, {'post_id': 3102, 'prediction': -0.8436636924743652}, {'post_id': 2043, 'prediction': -0.8325833678245544}, {'post_id': 262, 'prediction': -0.8186514377593994}, {'post_id': 2992, 'prediction': -0.7720634937286377}, {'post_id': 2925, 'prediction': -0.7716626524925232}, {'post_id': 607, 'prediction': -0.7671437859535217}, {'post_id': 1859, 'prediction': -0.7363873720169067}, {'post_id': 2165, 'prediction': -0.727554202079773}, {'post_id': 2408, 'prediction': -0.7219765186309814}, {'post_id': 1089, 'prediction': -0.6998317837715149}, {'post_id': 872, 'prediction': -0.6977895498275757}, {'post_id': 1588, 'prediction': -0.6899284720420837}, {'post_id': 2251, 'prediction': -0.6658449172973633}, {'post_id': 276, 'prediction': -0.6621386408805847}, {'post_id': 2236, 'prediction': -0.6612435579299927}, {'post_id': 3586, 'prediction': -0.6478399038314819}, {'post_id': 1152, 'prediction': -0.6404047608375549}, {'post_id': 1903, 'prediction': -0.63489830493927}, {'post_id': 374, 'prediction': -0.6244126558303833}]\n",
      "user_id = 242\n",
      "similarity_score =-0.759221556823808\n",
      "[{'post_id': 1909, 'prediction': -1.253955364227295}, {'post_id': 1088, 'prediction': -1.0538363456726074}, {'post_id': 1791, 'prediction': -1.0093891620635986}, {'post_id': 1190, 'prediction': -0.9482814073562622}, {'post_id': 1320, 'prediction': -0.9220961332321167}, {'post_id': 2427, 'prediction': -0.8995707631111145}, {'post_id': 344, 'prediction': -0.8693836331367493}, {'post_id': 2493, 'prediction': -0.8343777656555176}, {'post_id': 1194, 'prediction': -0.8200306296348572}, {'post_id': 2596, 'prediction': -0.801237165927887}, {'post_id': 3487, 'prediction': -0.7515672445297241}, {'post_id': 2961, 'prediction': -0.7452908158302307}, {'post_id': 2058, 'prediction': -0.7321673631668091}, {'post_id': 47, 'prediction': -0.7320664525032043}, {'post_id': 1222, 'prediction': -0.7292840480804443}, {'post_id': 3148, 'prediction': -0.7229040265083313}, {'post_id': 2236, 'prediction': -0.7207059860229492}, {'post_id': 756, 'prediction': -0.7138299345970154}, {'post_id': 1176, 'prediction': -0.705867350101471}, {'post_id': 3102, 'prediction': -0.7049770355224609}, {'post_id': 2322, 'prediction': -0.699775755405426}, {'post_id': 2679, 'prediction': -0.6944687962532043}, {'post_id': 3040, 'prediction': -0.680886447429657}, {'post_id': 3180, 'prediction': -0.6799695491790771}, {'post_id': 3310, 'prediction': -0.6728262901306152}, {'post_id': 2756, 'prediction': -0.6693574786186218}, {'post_id': 2907, 'prediction': -0.6673497557640076}, {'post_id': 1288, 'prediction': -0.6650466322898865}, {'post_id': 2063, 'prediction': -0.6615101099014282}, {'post_id': 795, 'prediction': -0.6435914039611816}]\n",
      "user_id = 226\n",
      "similarity_score =-0.7421612527584794\n",
      "[{'post_id': 268, 'prediction': -1.0267964601516724}, {'post_id': 344, 'prediction': -1.010661244392395}, {'post_id': 2493, 'prediction': -0.957602322101593}, {'post_id': 1909, 'prediction': -0.8885292410850525}, {'post_id': 1588, 'prediction': -0.8678267598152161}, {'post_id': 2043, 'prediction': -0.8521206974983215}, {'post_id': 2427, 'prediction': -0.8305780291557312}, {'post_id': 2992, 'prediction': -0.793203592300415}, {'post_id': 1971, 'prediction': -0.7574552297592163}, {'post_id': 2322, 'prediction': -0.7176594138145447}, {'post_id': 2925, 'prediction': -0.6765115261077881}, {'post_id': 1222, 'prediction': -0.6647173166275024}, {'post_id': 264, 'prediction': -0.6524136662483215}, {'post_id': 1190, 'prediction': -0.6471205949783325}, {'post_id': 531, 'prediction': -0.6107056140899658}, {'post_id': 719, 'prediction': -0.606950581073761}, {'post_id': 1088, 'prediction': -0.6064804196357727}, {'post_id': 2110, 'prediction': -0.5968526601791382}, {'post_id': 262, 'prediction': -0.5962200164794922}, {'post_id': 1320, 'prediction': -0.5875770449638367}, {'post_id': 1791, 'prediction': -0.5762478113174438}, {'post_id': 1056, 'prediction': -0.5731800198554993}, {'post_id': 2405, 'prediction': -0.5650310516357422}, {'post_id': 1194, 'prediction': -0.5640649795532227}, {'post_id': 891, 'prediction': -0.5621401071548462}, {'post_id': 626, 'prediction': -0.556537389755249}, {'post_id': 1859, 'prediction': -0.5532309412956238}, {'post_id': 933, 'prediction': -0.5472971796989441}, {'post_id': 3232, 'prediction': -0.5455067753791809}, {'post_id': 3586, 'prediction': -0.5442711710929871}]\n"
     ]
    }
   ],
   "source": [
    "opposite_users_recs = generate_sim_recs(ratings_file=ratingsPysparkDf,baseline_users=opposite_users,current_user_already_rated_posts=current_user_already_rated_posts,similar=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing on real users logic "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "matrix factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'post_id': 1190, 'prediction': 0.7996417880058289}\n",
      "{'post_id': 1190, 'prediction': 0.7017064735623817, 'baseline_user_id': 37, 'similarity_score': 0.7810509035373925, 'baseline_user_prediction': 0.8984132409095764}\n",
      "{'post_id': 268, 'prediction': 0.7620485471941373, 'baseline_user_id': 226, 'similarity_score': -0.7421612527584794, 'baseline_user_prediction': -1.0267964601516724}\n",
      "Necromancy within D&amp;amp;D isn't evil\n",
      "https://www.reddit.com//r/changemyview/comments/cl6iby/cmv_necromancy_within_dd_isnt_evil/\n",
      "Valid input\n",
      "Biological sex is not a social construct.\n",
      "https://www.reddit.com/r/changemyview/comments/82xw1t/cmv_biological_sex_is_not_a_social_construct/\n",
      "Valid input\n",
      "There are no negative effects because of the overall decline of spirituality...\n",
      "https://www.reddit.com//r/changemyview/comments/o0hbvq/cmv_there_are_no_negative_effects_because_of_the/\n",
      "Valid input\n",
      "Puberty blocks and gender reassignment surgery should not be given to kids u...\n",
      "https://www.reddit.com//r/changemyview/comments/vfxe6h/cmv_puberty_blocks_and_gender_reassignment/\n",
      "Valid input\n",
      "The inflation emergency was caused by corporate greed.\n",
      "https://www.reddit.com//r/changemyview/comments/uqxitr/cmv_the_inflation_emergency_was_caused_by/\n",
      "Valid input\n"
     ]
    }
   ],
   "source": [
    "for rec in matrix_factorization_predictions:\n",
    "    print(rec)\n",
    "    break\n",
    "for rec in similar_users_recs:\n",
    "    print(rec)\n",
    "    break\n",
    "for rec in opposite_users_recs:\n",
    "    print(rec)\n",
    "    break\n",
    "\n",
    "def test_matrix_factorization(recs=matrix_factorization_predictions,tolerance_limit=5):\n",
    "    import data_processing\n",
    "    num_rated_posts = 0\n",
    "    matrix_factorization_results = {}\n",
    "    for data in recs:\n",
    "        id = data['post_id']\n",
    "        res =data_processing.get_resource_info(id)\n",
    "        print(res['title'])\n",
    "        print(res['url'])\n",
    "        is_valid = input('Does the url provide enough info for you to understand the basic ideas expressed in this post?(Y/N):')\n",
    "        if is_valid.lower() == 'y':\n",
    "            print(\"Valid input\")\n",
    "            rec_score = float(input('How much did this recommended post make you see things trough a new perspective?:'))\n",
    "            matrix_factorization_results[id]={'user_score': rec_score, 'predicted_score':data['prediction'],'validity':True}\n",
    "            num_rated_posts +=1\n",
    "        else:\n",
    "            matrix_factorization_results[id]={'validity':False, 'predicted_score':data['prediction']}\n",
    "\n",
    "        current_user_already_rated_posts.add(id)\n",
    "        if num_rated_posts == tolerance_limit:\n",
    "            return matrix_factorization_results\n",
    "    return matrix_factorization_results\n",
    "\n",
    "\n",
    "matrix_factorization_results = test_matrix_factorization(matrix_factorization_predictions) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(current_user_already_rated_posts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "similar users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found already recommended post\n",
      "The police should use a hoplite phalanx formation to better deal with large ...\n",
      "https://www.reddit.com//r/changemyview/comments/jex8u5/cmv_the_police_should_use_a_hoplite_phalanx/\n",
      "Valid input\n",
      "found already recommended post\n",
      "Criticizing the Chinese government does not make you Sinophobic, Criticizing...\n",
      "https://www.reddit.com//r/changemyview/comments/loakbf/cmv_criticizing_the_chinese_government_does_not/\n",
      "Valid input\n",
      "having a messy room serves as a practice for walking through debris in emergency\n",
      "https://www.reddit.com/r/changemyview/comments/8g9eth/cmv_having_a_messy_room_serves_as_a_practice_for/\n",
      "Valid input\n",
      "found already recommended post\n",
      "Germany would be better off today if they won WW2\n",
      "https://www.reddit.com//r/changemyview/comments/an7dxl/cmv_germany_would_be_better_off_today_if_they_won/\n",
      "Valid input\n",
      "All content creators on the internet earn way too much money\n",
      "https://www.reddit.com//r/changemyview/comments/m1ao10/cmv_all_content_creators_on_the_internet_earn_way/\n",
      "Valid input\n"
     ]
    }
   ],
   "source": [
    "import data_processing\n",
    "def test_user_similarity_recommendations(baseline_users_recs,tolerance_limit =5):\n",
    "    num_rated_posts = 0\n",
    "    baseline_user_recs_results = {}\n",
    "    for data in baseline_users_recs:\n",
    "        res_id = data['post_id']\n",
    "        if res_id in current_user_already_rated_posts:\n",
    "            print('found already recommended post')\n",
    "            continue\n",
    "        \n",
    "        res = data_processing.get_resource_info(res_id)\n",
    "        baseline_user_id = data['baseline_user_id']\n",
    "        print(res['title'])\n",
    "        print(res['url'])\n",
    "        is_valid = input('Does the url provide enough info for you to understand the basic ideas expressed in this post?(Y/N):')\n",
    "        if is_valid.lower() == 'y':\n",
    "            print(\"Valid input\")\n",
    "            rec_score = float(input('How much did this recommended post make you see things trough a new perspective?:'))\n",
    "            baseline_user_recs_results[baseline_user_id]={'user_score': rec_score, 'rec_info':data,'validity':True}\n",
    "            num_rated_posts +=1\n",
    "        else:\n",
    "            baseline_user_recs_results[baseline_user_id]={'validity':False, 'rec_info':data}\n",
    "\n",
    "        current_user_already_rated_posts.add(res_id)\n",
    "        if num_rated_posts==tolerance_limit:\n",
    "            return baseline_user_recs_results\n",
    "    return baseline_user_recs_results\n",
    "\n",
    "\n",
    "similar_user_recs_results = test_user_similarity_recommendations(similar_users_recs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(current_user_already_rated_posts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Opposite users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found already recommended post\n",
      "Eating dogs is NOT more immoral than eating conventional meats.\n",
      "https://www.reddit.com//r/changemyview/comments/fw1uxi/cmv_eating_dogs_is_not_more_immoral_than_eating/\n",
      "Valid input\n",
      "The my body, my choice slogan for pro-choice advocates does not benefit th...\n",
      "https://www.reddit.com//r/changemyview/comments/jb2gut/cmv_the_my_body_my_choice_slogan_for_prochoice/\n",
      "Valid input\n",
      "found already recommended post\n",
      "Online dating has made finding a relationship impossible for all but the top...\n",
      "https://www.reddit.com//r/changemyview/comments/tvnps6/cmv_online_dating_has_made_finding_a_relationship/\n",
      "Valid input\n",
      "The US legislative and executive branches should be replaced by a randomly s...\n",
      "https://www.reddit.com//r/changemyview/comments/cuaj7z/cmv_the_us_legislative_and_executive_branches/\n",
      "Valid input\n",
      "California bill SB-827 would solve the state's housing crisis by allowing new housing to be built near transit hubs without local height, size, and design restrictions.\n",
      "https://www.reddit.com/r/changemyview/comments/82m92i/cmv_california_bill_sb827_would_solve_the_states/\n",
      "Valid input\n"
     ]
    }
   ],
   "source": [
    "opposite_user_recs_results = test_user_similarity_recommendations(opposite_users_recs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(current_user_already_rated_posts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "saving results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{226: {'user_score': 1.0, 'rec_info': {'post_id': 264, 'prediction': 0.4841961438596068, 'baseline_user_id': 226, 'similarity_score': -0.7421612527584794, 'baseline_user_prediction': -0.6524136662483215}, 'validity': True}}\n",
      "{37: {'user_score': 1.0, 'rec_info': {'post_id': 2236, 'prediction': 0.48958630986930535, 'baseline_user_id': 37, 'similarity_score': 0.7810509035373925, 'baseline_user_prediction': 0.6268302202224731}, 'validity': True}}\n",
      "{1190: {'user_score': 1.0, 'predicted_score': 0.7996417880058289, 'validity': True}, 268: {'user_score': 1.0, 'predicted_score': 0.7205122709274292, 'validity': True}, 2570: {'user_score': 1.0, 'predicted_score': 0.6130921244621277, 'validity': True}, 3040: {'user_score': 1.0, 'predicted_score': 0.6093191504478455, 'validity': True}, 2992: {'user_score': 1.0, 'predicted_score': 0.5738112330436707, 'validity': True}}\n",
      "tes\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "print(opposite_user_recs_results)\n",
    "print(similar_user_recs_results)\n",
    "print(matrix_factorization_results)\n",
    "print(name)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "RESULTS_FOLDER_LOCATION = \"collaborative_filtering_results\"\n",
    "results_file_location = os.path.join(RESULTS_FOLDER_LOCATION,name+'_collaborative_filtering.json')\n",
    "\n",
    "results_file = open(results_file_location,'w')\n",
    "\n",
    "final_user_result={\n",
    "    'name': name,\n",
    "    'id':user_id,\n",
    "    'matrix_factorization':matrix_factorization_results,\n",
    "    'similar_users':similar_user_recs_results,\n",
    "    'opposite_users':opposite_user_recs_results\n",
    "}\n",
    "json.dump(final_user_result,results_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loading results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'tes', 'id': 295, 'matrix_factorization': {'1190': {'user_score': 1.0, 'predicted_score': 0.7996417880058289, 'validity': True}, '268': {'user_score': 1.0, 'predicted_score': 0.7205122709274292, 'validity': True}, '2570': {'user_score': 1.0, 'predicted_score': 0.6130921244621277, 'validity': True}, '3040': {'user_score': 1.0, 'predicted_score': 0.6093191504478455, 'validity': True}, '2992': {'user_score': 1.0, 'predicted_score': 0.5738112330436707, 'validity': True}}, 'similar_users': {'37': {'user_score': 1.0, 'rec_info': {'post_id': 2236, 'prediction': 0.48958630986930535, 'baseline_user_id': 37, 'similarity_score': 0.7810509035373925, 'baseline_user_prediction': 0.6268302202224731}, 'validity': True}}, 'opposite_users': {'226': {'user_score': 1.0, 'rec_info': {'post_id': 264, 'prediction': 0.4841961438596068, 'baseline_user_id': 226, 'similarity_score': -0.7421612527584794, 'baseline_user_prediction': -0.6524136662483215}, 'validity': True}}}\n"
     ]
    }
   ],
   "source": [
    "results_file = open(results_file_location,'r')\n",
    "\n",
    "print(json.load(results_file))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
