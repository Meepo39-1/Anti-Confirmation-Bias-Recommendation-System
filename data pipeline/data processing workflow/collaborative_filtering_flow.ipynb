{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'c:\\\\Users\\\\A&A\\\\Desktop\\\\Anti Confirmation Bias Recommendation System\\\\data pipeline\\\\data processing workflow\\\\data pipeline\\\\data processing workflow\\\\data processing session\\\\resources_info.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdata_processing\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#load data\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[43mdata_processing\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_resources_from_raw_delta_logs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmin_num_interactions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m data_processing\u001b[38;5;241m.\u001b[39mload_users(min_num_interactions\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m      6\u001b[0m data_processing\u001b[38;5;241m.\u001b[39mcompute_ratings()\n",
      "File \u001b[1;32mc:\\Users\\A&A\\Desktop\\Anti Confirmation Bias Recommendation System\\data pipeline\\data processing workflow\\data_processing.py:197\u001b[0m, in \u001b[0;36mload_resources_from_raw_delta_logs\u001b[1;34m(out_file, min_num_interactions)\u001b[0m\n\u001b[0;32m    195\u001b[0m     delta_logs_file\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m    196\u001b[0m \u001b[38;5;66;03m#print(current_working_directory)          \u001b[39;00m\n\u001b[1;32m--> 197\u001b[0m \u001b[43mextract_resources_from_delta_logs_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdelta_logs_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmin_num_interactions\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\A&A\\Desktop\\Anti Confirmation Bias Recommendation System\\data pipeline\\data processing workflow\\data_processing.py:179\u001b[0m, in \u001b[0;36mload_resources_from_raw_delta_logs.<locals>.extract_resources_from_delta_logs_file\u001b[1;34m(res_file_path, delta_logs_file_path, min_num_interactions, tolerance_limit)\u001b[0m\n\u001b[0;32m    177\u001b[0m id_res \u001b[38;5;241m=\u001b[39m collections\u001b[38;5;241m.\u001b[39mdefaultdict()\n\u001b[0;32m    178\u001b[0m res_id \u001b[38;5;241m=\u001b[39m collections\u001b[38;5;241m.\u001b[39mdefaultdict()\n\u001b[1;32m--> 179\u001b[0m res_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mres_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    180\u001b[0m delta_logs_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(delta_logs_file_path,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m,encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    181\u001b[0m titles \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'c:\\\\Users\\\\A&A\\\\Desktop\\\\Anti Confirmation Bias Recommendation System\\\\data pipeline\\\\data processing workflow\\\\data pipeline\\\\data processing workflow\\\\data processing session\\\\resources_info.txt'"
     ]
    }
   ],
   "source": [
    "import data_processing\n",
    "\n",
    "#load data\n",
    "data_processing.load_resources_from_raw_delta_logs(min_num_interactions=6)\n",
    "data_processing.load_users(min_num_interactions=10)\n",
    "data_processing.compute_ratings()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data pipeline\\\\data processing workflow\\\\data processing session\\\\extracted_ratings'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata pipeline\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdata processing workflow\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdata processing session\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mextracted_ratings\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 2\u001b[0m file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\A&A\\Desktop\\Anti Confirmation Bias Recommendation System\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data pipeline\\\\data processing workflow\\\\data processing session\\\\extracted_ratings'"
     ]
    }
   ],
   "source": [
    "path = r'data pipeline\\data processing workflow\\data processing session\\extracted_ratings'\n",
    "file = open(path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "[PATH_NOT_FOUND] Path does not exist: file:/c:/Users/A&A/Desktop/Anti Confirmation Bias Recommendation System/data pipeline/data processing workflow/data pipeline/data processing workflow/data processing session/extracted_ratings.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 92\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRoot-mean-square error = \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(rmse))\n\u001b[0;32m     90\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (ratings,model,rmse)\n\u001b[1;32m---> 92\u001b[0m ratingsPysparkDf,model,rmse \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_matrix_factorization\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 69\u001b[0m, in \u001b[0;36mcompute_matrix_factorization\u001b[1;34m()\u001b[0m\n\u001b[0;32m     64\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata pipeline\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdata processing workflow\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdata processing session\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mextracted_ratings\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     66\u001b[0m spark \u001b[38;5;241m=\u001b[39m SparkSession\u001b[38;5;241m.\u001b[39mbuilder\u001b[38;5;241m.\u001b[39mappName(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCollaborative Filtering Flow\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mgetOrCreate()\n\u001b[1;32m---> 69\u001b[0m lines \u001b[38;5;241m=\u001b[39m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mrdd\n\u001b[0;32m     71\u001b[0m parts \u001b[38;5;241m=\u001b[39m lines\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m row: row\u001b[38;5;241m.\u001b[39mvalue\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m     72\u001b[0m ratingsRDD \u001b[38;5;241m=\u001b[39m parts\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m p: Row(userId\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m(p[\u001b[38;5;241m0\u001b[39m]), postId\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m(p[\u001b[38;5;241m1\u001b[39m]),\n\u001b[0;32m     73\u001b[0m                                     rating\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfloat\u001b[39m(p[\u001b[38;5;241m2\u001b[39m]) ))\n",
      "File \u001b[1;32mc:\\Users\\A&A\\Desktop\\Anti Confirmation Bias Recommendation System\\env\\lib\\site-packages\\pyspark\\sql\\readwriter.py:615\u001b[0m, in \u001b[0;36mDataFrameReader.text\u001b[1;34m(self, paths, wholetext, lineSep, pathGlobFilter, recursiveFileLookup, modifiedBefore, modifiedAfter)\u001b[0m\n\u001b[0;32m    613\u001b[0m     paths \u001b[38;5;241m=\u001b[39m [paths]\n\u001b[0;32m    614\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_spark\u001b[38;5;241m.\u001b[39m_sc\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 615\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_df(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_spark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPythonUtils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoSeq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpaths\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\A&A\\Desktop\\Anti Confirmation Bias Recommendation System\\env\\lib\\site-packages\\py4j\\java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\A&A\\Desktop\\Anti Confirmation Bias Recommendation System\\env\\lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    181\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mAnalysisException\u001b[0m: [PATH_NOT_FOUND] Path does not exist: file:/c:/Users/A&A/Desktop/Anti Confirmation Bias Recommendation System/data pipeline/data processing workflow/data pipeline/data processing workflow/data processing session/extracted_ratings."
     ]
    }
   ],
   "source": [
    "# from pyspark.sql import SparkSession\n",
    "# from pyspark.sql.functions import col \n",
    "# from pyspark.ml.evaluation import RegressionEvaluator\n",
    "# from pyspark.ml.recommendation import ALS\n",
    "# from pyspark.sql import Row\n",
    "# import os\n",
    "# import sys\n",
    "\n",
    "# # os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "# # os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "\n",
    "# import data_processing\n",
    "# import findspark\n",
    "\n",
    "# findspark.init()\n",
    "\n",
    "\n",
    "\n",
    "# spark = SparkSession.builder.appName(\"Collaborative Filtering Flow\").getOrCreate()\n",
    "\n",
    "\n",
    "# path = r'C:\\Users\\A&A\\Downloads\\Date Personale Laptop Nagarro\\Proiect Licenta\\data pipeline\\data processing workflow\\data processing session\\extracted_ratings'\n",
    "\n",
    "\n",
    "# lines = spark.read.text(path).rdd\n",
    "\n",
    "# parts = lines.map(lambda row: row.value.split(\" \"))\n",
    "# ratingsRDD = parts.map(lambda p: Row(userId=int(p[0]), movieId=int(p[1]),\n",
    "#                                       rating=float(p[2]) ))\n",
    "\n",
    "\n",
    "# ratings = spark.createDataFrame(ratingsRDD)\n",
    "# (training, test) = ratings, ratings\n",
    "# # # Build the recommendation model using ALS on the training data\n",
    "# # # Note we set cold start strategy to 'drop' to ensure we don't get NaN evaluation metrics\n",
    "# als = ALS(maxIter=5, regParam=0.01, userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\",\n",
    "#            coldStartStrategy=\"drop\")\n",
    "# model = als.fit(training)\n",
    "\n",
    "# # # Evaluate the model by computing the RMSE on the test data\n",
    "# predictions = model.transform(test)\n",
    "# evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",\n",
    "#                                  predictionCol=\"prediction\")\n",
    "# rmse = evaluator.evaluate(predictions)\n",
    "# print(\"Root-mean-square error = \" + str(rmse))\n",
    "\n",
    "def compute_matrix_factorization():\n",
    "    from pyspark.sql import SparkSession\n",
    "    from pyspark.sql.functions import col \n",
    "    from pyspark.ml.evaluation import RegressionEvaluator\n",
    "    from pyspark.ml.recommendation import ALS\n",
    "    from pyspark.sql import Row\n",
    "    import os\n",
    "    import sys\n",
    "\n",
    "    # os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "    # os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "\n",
    "    import data_processing\n",
    "    import findspark\n",
    "\n",
    "    findspark.init()\n",
    "\n",
    "    path = r'data pipeline\\data processing workflow\\data processing session\\extracted_ratings'\n",
    "    spark = SparkSession.builder.appName(\"Collaborative Filtering Flow\").getOrCreate()\n",
    "\n",
    "\n",
    "    lines = spark.read.text(path).rdd\n",
    "\n",
    "    parts = lines.map(lambda row: row.value.split(\" \"))\n",
    "    ratingsRDD = parts.map(lambda p: Row(userId=int(p[0]), postId=int(p[1]),\n",
    "                                        rating=float(p[2]) ))\n",
    "\n",
    "\n",
    "    ratings = spark.createDataFrame(ratingsRDD)\n",
    "    (training, test) = ratings, ratings\n",
    "    # # Build the recommendation model using ALS on the training data\n",
    "    # # Note we set cold start strategy to 'drop' to ensure we don't get NaN evaluation metrics\n",
    "    als = ALS(maxIter=5, regParam=0.01, userCol=\"userId\", itemCol=\"postId\", ratingCol=\"rating\",\n",
    "            coldStartStrategy=\"drop\")\n",
    "    model = als.fit(training)\n",
    "\n",
    "    # # Evaluate the model by computing the RMSE on the test data\n",
    "    predictions = model.transform(test)\n",
    "    evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",\n",
    "                                    predictionCol=\"prediction\")\n",
    "    rmse = evaluator.evaluate(predictions)\n",
    "    print(\"Root-mean-square error = \" + str(rmse))\n",
    "    return (ratings,model,rmse)\n",
    "\n",
    "ratingsPysparkDf,model,rmse = compute_matrix_factorization()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract resources relevant to the latent factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_baseline_posts(model,cached=True):\n",
    "    import data_processing\n",
    "    titles =[\n",
    "        \"Infidelity should not happen when divorce is possible\",\n",
    "         \"The default world lingua franca should be Spanish\",\n",
    "         \"Buying clothes or goods from factories in the developing world is moral, eve...\",\n",
    "         \"The legal owner of a firearm should be responsible for the weapon and anythi...\",\n",
    "         \"Airport security screenings do very little to stop deliberate terrorism such as the attacks of 9/11. They are a show put on to make passengers think something is being done.\",\n",
    "         \"Luxury watches are useless in the practical sense\",\n",
    "         \"The concept of an omniscient (*) and capable creator is not compatible with ...\",\n",
    "         \"If whatever makes your character different (sexual identity/disability etc) ...\",\n",
    "         \"Cutlery should be placed at the end of a buffet line\",\n",
    "         \"If an animal has a big enough population, hunting of it should be allowed\"\n",
    "]\n",
    "    \n",
    "    if cached:\n",
    "        baseline_posts = []\n",
    "        for title in titles:\n",
    "            #print(title)\n",
    "            id = data_processing.res_id[title]\n",
    "            #print(id)\n",
    "            baseline_posts.append(data_processing.get_resource_info(id))\n",
    "        return baseline_posts\n",
    "    else:    \n",
    "        '''After advisor approval, these posts shall be hardcoded '''\n",
    "\n",
    "        from pyspark.sql.functions import expr\n",
    "\n",
    "        # Extract item factors\n",
    "        item_factors = model.itemFactors\n",
    "\n",
    "        # Find the top 5 highest scores for each latent factor\n",
    "        num_factors = model.rank  # Number of latent factors\n",
    "        top_scores_per_factor = []\n",
    "\n",
    "        for i in range(num_factors):\n",
    "            factor_col = expr(f\"features[{i}]\")\n",
    "            top_rows = (item_factors\n",
    "                        .select(\"id\", factor_col.alias(\"factor\"))\n",
    "                        .orderBy(\"factor\", ascending=False)\n",
    "                        .limit(10)\n",
    "                        .collect())\n",
    "            top_scores_per_factor.append((i, [(row.id, row.factor) for row in top_rows]))\n",
    "\n",
    "        #for the final version, the resources will be predefined, to ensure that the reddit posts are not deprecated\n",
    "        baseline_posts = []\n",
    "        for factor, top_scores in top_scores_per_factor:\n",
    "            for rank, (post_id, factor_score) in enumerate(top_scores, start=1):\n",
    "                if rank ==1:\n",
    "                    baseline_posts.append({'id':post_id,'score':factor_score,'content':data_processing.id_res[post_id]})\n",
    "                print(f'title:{data_processing.id_res[post_id][\"title\"]},url:{data_processing.id_res[post_id][\"url\"]},factor {factor},score:{factor_score}')\n",
    "            print(\"-\"*100)\n",
    "        return baseline_posts\n",
    "\n",
    "baseline_posts = extract_baseline_posts(model,cached=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "344"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles =[\"Infidelity should not happen when divorce is possible\"]\n",
    "data_processing.get_resource_id(\"The default world lingua franca should be Spanish\")\n",
    "data_processing.get_resource_id(\"Buying clothes or goods from factories in the developing world is moral, eve...\")\n",
    "data_processing.get_resource_id(\"The legal owner of a firearm should be responsible for the weapon and anythi...\")\n",
    "data_processing.get_resource_id(\"Airport security screenings do very little to stop deliberate terrorism such as the attacks of 9/11. They are a show put on to make passengers think something is being done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'Infidelity should not happen when divorce is possible', 'pos_feedback': ['Nitrousoxide72', 'RedditExplorer89'], 'neg_feedback': ['ripcelinedionhusband', 'Melodic_Echidna', 'joopface', 'dublea', 'ripcelinedionhusband', 'WelfareBear', 'JimboMan1234', '', 'muyamable', 'Nephisimian', 'USoverthem'], 'url': 'https://www.reddit.com//r/changemyview/comments/imh6iw/cmv_infidelity_should_not_happen_when_divorce_is/'}\n"
     ]
    }
   ],
   "source": [
    "print(baseline_posts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 [{'title': 'Infidelity should not happen when divorce is possible', 'pos_feedback': ['Nitrousoxide72', 'RedditExplorer89'], 'neg_feedback': ['ripcelinedionhusband', 'Melodic_Echidna', 'joopface', 'dublea', 'ripcelinedionhusband', 'WelfareBear', 'JimboMan1234', '', 'muyamable', 'Nephisimian', 'USoverthem'], 'url': 'https://www.reddit.com//r/changemyview/comments/imh6iw/cmv_infidelity_should_not_happen_when_divorce_is/'}, {'title': 'The default world lingua franca should be Spanish', 'pos_feedback': ['NicholasLeo', 'BrotherItsInTheDrum'], 'neg_feedback': ['Igor_Furman', 'muyamable', '', 'MontiBurns', '', 'parentheticalobject'], 'url': 'https://www.reddit.com//r/changemyview/comments/hf49v5/cmv_the_default_world_lingua_franca_should_be/'}, {'title': 'Buying clothes or goods from factories in the developing world is moral, eve...', 'pos_feedback': ['mr-logician', 'thedobya'], 'neg_feedback': ['AnythingApplied', 'AnythingApplied', 'MercurianAspirations', 'StellaAthena'], 'url': 'https://www.reddit.com//r/changemyview/comments/dwebfc/cmv_buying_clothes_or_goods_from_factories_in_the/'}, {'title': 'The legal owner of a firearm should be responsible for the weapon and anythi...', 'pos_feedback': ['BoredRedhead'], 'neg_feedback': ['Missing_Links', 'Fanfic_Galore', 'BoyMeetsTheWorld', 'MechanicalEngineEar', 'Servant-Ruler', 'Lilah_R', 'VoodooManchester', 'DBDude', 'NastyNNaughty69', '', '600062'], 'url': 'https://www.reddit.com//r/changemyview/comments/i4f917/cmv_the_legal_owner_of_a_firearm_should_be/'}, {'title': 'Airport security screenings do very little to stop deliberate terrorism such as the attacks of 9/11. They are a show put on to make passengers think something is being done.', 'pos_feedback': ['TheloniusMusk', 'florencenightinjale'], 'neg_feedback': ['hacksoncode', 'MyUsernameIsJudge', '', 'Ansuz07', 'thisisnotariot', '', 'apparentlyapparent'], 'url': 'https://www.reddit.com/r/changemyview/comments/8a9r3h/cmv_airport_security_screenings_do_very_little_to/'}, {'title': 'Luxury watches are useless in the practical sense', 'pos_feedback': ['Crayshack', 'avatarlegend12345'], 'neg_feedback': ['KDY_ISD', 'KDY_ISD', 'HallucinatoryWalnut', 'a_sack_of_hamsters'], 'url': 'https://www.reddit.com//r/changemyview/comments/bvupnz/cmv_luxury_watches_are_useless_in_the_practical/'}, {'title': 'The concept of an omniscient (*) and capable creator is not compatible with ...', 'pos_feedback': ['Salty_Dornishman', 'PivotPsycho'], 'neg_feedback': ['badass_panda', 'JoZeHgS', 'wajubop', 'ButtonholePhotophile', 'MizunoGolfer15-20', 'NicholasLeo'], 'url': 'https://www.reddit.com//r/changemyview/comments/lbqam1/cmv_the_concept_of_an_omniscient_and_capable/'}, {'title': 'If whatever makes your character different (sexual identity/disability etc) ...', 'pos_feedback': ['GnosticGnome', 'doriangraiy'], 'neg_feedback': ['th3empirial', 'BeatriceBernardo', 'HazelGhost', 'adhd_energy_'], 'url': 'https://www.reddit.com//r/changemyview/comments/mu84wm/cmv_if_whatever_makes_your_character_different/'}, {'title': 'Cutlery should be placed at the end of a buffet line', 'pos_feedback': ['zfreakazoidz', 'Herbie_Fully_Loaded'], 'neg_feedback': ['ralph-j', 'dublea', '', 'ThinkingAboutJulia', 'erection_detection_', 'pawnman99', 'badass_panda'], 'url': 'https://www.reddit.com//r/changemyview/comments/n6y914/cmv_cutlery_should_be_placed_at_the_end_of_a/'}, {'title': 'If an animal has a big enough population, hunting of it should be allowed', 'pos_feedback': ['overhardeggs'], 'neg_feedback': ['GoblinRaiders', 'NowImAllSet', 'destro23', 'destro23', 'wantingtodobetter', 'drschwartz', '', 'hacksoncode'], 'url': 'https://www.reddit.com//r/changemyview/comments/w9hy6t/cmv_if_an_animal_has_a_big_enough_population/'}]\n"
     ]
    }
   ],
   "source": [
    "print(len(baseline_posts),baseline_posts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect data for cold start problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title:Infidelity should not happen when divorce is possible\n",
      "url: https://www.reddit.com//r/changemyview/comments/imh6iw/cmv_infidelity_should_not_happen_when_divorce_is/\n",
      "Title:The default world lingua franca should be Spanish\n",
      "url: https://www.reddit.com//r/changemyview/comments/hf49v5/cmv_the_default_world_lingua_franca_should_be/\n",
      "Title:Buying clothes or goods from factories in the developing world is moral, eve...\n",
      "url: https://www.reddit.com//r/changemyview/comments/dwebfc/cmv_buying_clothes_or_goods_from_factories_in_the/\n",
      "Title:The legal owner of a firearm should be responsible for the weapon and anythi...\n",
      "url: https://www.reddit.com//r/changemyview/comments/i4f917/cmv_the_legal_owner_of_a_firearm_should_be/\n",
      "Title:Airport security screenings do very little to stop deliberate terrorism such as the attacks of 9/11. They are a show put on to make passengers think something is being done.\n",
      "url: https://www.reddit.com/r/changemyview/comments/8a9r3h/cmv_airport_security_screenings_do_very_little_to/\n",
      "Title:Luxury watches are useless in the practical sense\n",
      "url: https://www.reddit.com//r/changemyview/comments/bvupnz/cmv_luxury_watches_are_useless_in_the_practical/\n",
      "Title:The concept of an omniscient (*) and capable creator is not compatible with ...\n",
      "url: https://www.reddit.com//r/changemyview/comments/lbqam1/cmv_the_concept_of_an_omniscient_and_capable/\n",
      "Title:If whatever makes your character different (sexual identity/disability etc) ...\n",
      "url: https://www.reddit.com//r/changemyview/comments/mu84wm/cmv_if_whatever_makes_your_character_different/\n",
      "Title:Cutlery should be placed at the end of a buffet line\n",
      "url: https://www.reddit.com//r/changemyview/comments/n6y914/cmv_cutlery_should_be_placed_at_the_end_of_a/\n",
      "Title:If an animal has a big enough population, hunting of it should be allowed\n",
      "url: https://www.reddit.com//r/changemyview/comments/w9hy6t/cmv_if_an_animal_has_a_big_enough_population/\n"
     ]
    }
   ],
   "source": [
    "def init_cold_start(baseline_posts,cached=True):\n",
    "\n",
    "    import data_processing\n",
    "\n",
    "    name = input(\"Please write your name:\")\n",
    "    description = \"Dummy description of the task\"\n",
    "\n",
    "    baseline_results =[]\n",
    "\n",
    "    if cached:\n",
    "        for res in baseline_posts:\n",
    "            print(f'Title:{res[\"title\"]}')\n",
    "            print(f'url: {res[\"url\"]}')\n",
    "            baseline_score = float(input('How much did this post make you see things trough a new perspective?:'))\n",
    "            baseline_results.append({'id':data_processing.res_id[res['title']],'user_score':baseline_score})\n",
    "        return (baseline_results,name)\n",
    "    else:\n",
    "        for baseline_post in baseline_posts:\n",
    "            res = baseline_post[\"content\"]\n",
    "            print(f'Title:{res[\"title\"]}')\n",
    "            print(f'url: {res[\"url\"]}')\n",
    "            baseline_score = float(input('How much did this post make you see things trough a new perspective?:'))\n",
    "            baseline_results.append({'id':baseline_post['id'],'factor_score':baseline_post['score'],'user_score':baseline_score})\n",
    "        return (baseline_results,name)\n",
    "\n",
    "\n",
    "baseline_results,name = init_cold_start(baseline_posts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the model with the new user's data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294\n"
     ]
    }
   ],
   "source": [
    "def add_new_user_ratings(baseline_results):\n",
    "    ratings_path_file = r'C:\\Users\\A&A\\Downloads\\Date Personale Laptop Nagarro\\Proiect Licenta\\data pipeline\\data processing workflow\\data processing session\\extracted_ratings'\n",
    "\n",
    "    ratings_file = open(ratings_path_file,'r')\n",
    "\n",
    "\n",
    "    for line in ratings_file:\n",
    "        last_line = line\n",
    "    last_line = last_line.split(\" \")\n",
    "    new_user_id = int(last_line[0]) + 1\n",
    "    print(new_user_id)\n",
    "    ratings_file.close()\n",
    "    ratings_file = open(ratings_path_file,'a')\n",
    "\n",
    "    for result in baseline_results:\n",
    "        #ratings_file.write()\n",
    "        res_id = result['id']\n",
    "        score = result['user_score']\n",
    "        ratings_file.write(f'{new_user_id} {res_id} {score}\\n')\n",
    "        #print(f'{new_user_id} {res_id} {score}\\n')\n",
    "    ratings_file.close()\n",
    "    return new_user_id\n",
    "user_id = add_new_user_ratings(baseline_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error = 0.01893034984413313\n"
     ]
    }
   ],
   "source": [
    "def compute_matrix_factorization():\n",
    "    from pyspark.sql import SparkSession\n",
    "    from pyspark.sql.functions import col \n",
    "    from pyspark.ml.evaluation import RegressionEvaluator\n",
    "    from pyspark.ml.recommendation import ALS\n",
    "    from pyspark.sql import Row\n",
    "    import os\n",
    "    import sys\n",
    "\n",
    "    # os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "    # os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "\n",
    "    import data_processing\n",
    "    import findspark\n",
    "\n",
    "    findspark.init()\n",
    "\n",
    "    path = r'C:\\Users\\A&A\\Downloads\\Date Personale Laptop Nagarro\\Proiect Licenta\\data pipeline\\data processing workflow\\data processing session\\extracted_ratings'\n",
    "\n",
    "    spark = SparkSession.builder.appName(\"Collaborative Filtering Flow\").getOrCreate()\n",
    "\n",
    "\n",
    "    lines = spark.read.text(path).rdd\n",
    "\n",
    "    parts = lines.map(lambda row: row.value.split(\" \"))\n",
    "    ratingsRDD = parts.map(lambda p: Row(userId=int(p[0]), postId=int(p[1]),\n",
    "                                        rating=float(p[2]) ))\n",
    "\n",
    "\n",
    "    ratings = spark.createDataFrame(ratingsRDD)\n",
    "    (training, test) = ratings, ratings\n",
    "    # # Build the recommendation model using ALS on the training data\n",
    "    # # Note we set cold start strategy to 'drop' to ensure we don't get NaN evaluation metrics\n",
    "    als = ALS(maxIter=5, regParam=0.01, userCol=\"userId\", itemCol=\"postId\", ratingCol=\"rating\",\n",
    "            coldStartStrategy=\"drop\")\n",
    "    model = als.fit(training)\n",
    "\n",
    "    # # Evaluate the model by computing the RMSE on the test data\n",
    "    predictions = model.transform(test)\n",
    "    evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",\n",
    "                                    predictionCol=\"prediction\")\n",
    "    rmse = evaluator.evaluate(predictions)\n",
    "    print(\"Root-mean-square error = \" + str(rmse))\n",
    "    return (ratings,model,rmse)\n",
    "\n",
    "ratingsPysparkDf,model,rmse = compute_matrix_factorization()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make recommendations for the new user based on matrix factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract ids of already rated posts by user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_posts_already_rated(ratings,user_id = 294):\n",
    "    from pyspark.sql.functions import col \n",
    "    user_ratings = ratings.filter(col(\"userId\") == 294).select(\"postId\").distinct()\n",
    "    posts_rated_by_user = set()\n",
    "\n",
    "    for post_id in user_ratings.toPandas().values:\n",
    "        posts_rated_by_user.add(post_id[0])\n",
    "\n",
    "    #print(posts_rated_by_user)\n",
    "    return posts_rated_by_user\n",
    "current_user_already_rated_posts = extract_posts_already_rated(ratingsPysparkDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_recommendations = model.recommendForAllUsers(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------------------------------------------------------+\n",
      "|userId|recommendations                                          |\n",
      "+------+---------------------------------------------------------+\n",
      "|294   |[{1972, 1.3016436}, {1279, 1.1852648}, {2322, 1.0094897}]|\n",
      "+------+---------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#This posts have already been rated by the user\n",
    "\n",
    "user_recommendations.filter(user_recommendations.userId==294).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'post_id': 1972, 'prediction': 1.3016436100006104}, {'post_id': 1279, 'prediction': 1.1852648258209229}, {'post_id': 2816, 'prediction': 0.9350828528404236}, {'post_id': 2118, 'prediction': 0.9242882132530212}, {'post_id': 2801, 'prediction': 0.9189030528068542}, {'post_id': 2382, 'prediction': 0.8939732313156128}, {'post_id': 2016, 'prediction': 0.8786962628364563}, {'post_id': 2070, 'prediction': 0.8668661713600159}, {'post_id': 2546, 'prediction': 0.8338358402252197}, {'post_id': 1420, 'prediction': 0.8120893836021423}, {'post_id': 2925, 'prediction': 0.8095897436141968}, {'post_id': 1826, 'prediction': 0.8074844479560852}, {'post_id': 3661, 'prediction': 0.7994099259376526}, {'post_id': 2561, 'prediction': 0.7991224527359009}, {'post_id': 1288, 'prediction': 0.7989335060119629}]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col,lit\n",
    "\n",
    "def generate_matrix_factorization_recs(ratingsPysparkDf,user_id = 294,number_recs=15,similar=True):\n",
    "    \n",
    "    # Generate recommendations for a specific user\n",
    "    user_ratings = ratingsPysparkDf.filter(col(\"userId\") == user_id).select(\"postId\").distinct()\n",
    "    #user_ratings.show()\n",
    "    all_posts = ratingsPysparkDf.select(\"postId\").distinct()\n",
    "    posts_not_rated_by_user = all_posts.join(user_ratings, on=\"postId\", how=\"left_anti\")\n",
    "\n",
    "    #posts_not_rated_by_user.show()\n",
    "\n",
    "    # Recommend top number_recs posts\n",
    "    posts_not_rated_by_user = posts_not_rated_by_user.withColumn(\"userId\", lit(user_id))\n",
    "    recommendations = model.transform(posts_not_rated_by_user)\n",
    "    if similar:\n",
    "        top_recommendations = recommendations.orderBy(col(\"prediction\").desc()).select(\"postId\", \"prediction\").limit(number_recs)\n",
    "    else:\n",
    "        top_recommendations = recommendations.orderBy(col(\"prediction\")).select(\"postId\", \"prediction\").limit(number_recs)\n",
    "\n",
    "    #top_recommendations.show()\n",
    "\n",
    "\n",
    "    #extract them in a list\n",
    "    postIds = [p[0] for p in top_recommendations.select(\"postId\").toPandas().values.tolist()]\n",
    "    predictions = [p[0] for p in top_recommendations.select(\"prediction\").toPandas().values.tolist()]\n",
    "\n",
    "    #print(postIds)\n",
    "    #print(predictions)\n",
    "\n",
    "    matrix_factorization_predictions = []\n",
    "    for index in range(len(postIds)):\n",
    "        matrix_factorization_predictions.append({'post_id':postIds[index],'prediction':predictions[index]})\n",
    "    print(matrix_factorization_predictions)\n",
    "    return matrix_factorization_predictions\n",
    "\n",
    "matrix_factorization_predictions = generate_matrix_factorization_recs(ratingsPysparkDf,user_id = 294,similar=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#after rating\n",
    "# for rec in matrix_factorization_predictions:\n",
    "#     current_user_already_rated_posts.add(rec['post_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make recommendations for the new user based on similar and opposite users\n",
    "\n",
    "### Make recommendations based on similar users\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create similarity matrix of users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          2         3         4         5         6         7         8    \\\n",
      "2    1.000000  0.620373 -0.309166 -0.630209 -0.154972  0.243693  0.265376   \n",
      "3    0.620373  1.000000  0.326082 -0.187345  0.163884  0.077048 -0.433572   \n",
      "4   -0.309166  0.326082  1.000000  0.513037  0.352590  0.095308 -0.644196   \n",
      "5   -0.630209 -0.187345  0.513037  1.000000  0.058923  0.029083 -0.683051   \n",
      "6   -0.154972  0.163884  0.352590  0.058923  1.000000  0.627839 -0.128139   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "290 -0.146571 -0.036821  0.363455  0.350617  0.365622  0.175629 -0.019268   \n",
      "291 -0.015836  0.245979  0.257006 -0.144499  0.422861  0.415727 -0.090254   \n",
      "292  0.260809  0.345747 -0.004083  0.158294  0.068723  0.237544 -0.489750   \n",
      "293  0.079526  0.465311  0.438634 -0.198878  0.665281  0.305087 -0.184205   \n",
      "294 -0.259154 -0.057764  0.108687  0.139631 -0.423141 -0.461920 -0.206150   \n",
      "\n",
      "          9         10        11   ...       285       286       287  \\\n",
      "2    0.093239 -0.182040  0.039903  ...  0.088161  0.089716 -0.447414   \n",
      "3   -0.397413 -0.455773  0.318122  ... -0.020113  0.073451 -0.049191   \n",
      "4   -0.166743 -0.286663  0.590235  ...  0.173367 -0.101294  0.516667   \n",
      "5    0.162804 -0.047976  0.232465  ... -0.137055 -0.090751  0.264446   \n",
      "6   -0.030479 -0.005159  0.221821  ...  0.395747  0.503762  0.182802   \n",
      "..        ...       ...       ...  ...       ...       ...       ...   \n",
      "290  0.431586 -0.423433  0.198196  ...  0.412293  0.407386  0.226084   \n",
      "291 -0.390318  0.235592  0.464303  ...  0.607389  0.279647  0.035832   \n",
      "292 -0.273770 -0.424698 -0.208580  ...  0.092509 -0.270191 -0.096038   \n",
      "293 -0.577907 -0.353076  0.339228  ...  0.534397  0.357833  0.075611   \n",
      "294 -0.571330 -0.265090  0.123471  ...  0.198427 -0.150158 -0.026532   \n",
      "\n",
      "          288       289       290       291       292       293       294  \n",
      "2   -0.200591  0.311795 -0.146571 -0.015836  0.260809  0.079526 -0.259154  \n",
      "3    0.148196  0.484058 -0.036821  0.245979  0.345747  0.465311 -0.057764  \n",
      "4    0.185977  0.512203  0.363455  0.257006 -0.004083  0.438634  0.108687  \n",
      "5   -0.045108  0.044411  0.350617 -0.144499  0.158294 -0.198878  0.139631  \n",
      "6    0.074420 -0.038438  0.365622  0.422861  0.068723  0.665281 -0.423141  \n",
      "..        ...       ...       ...       ...       ...       ...       ...  \n",
      "290 -0.643990  0.047258  1.000000 -0.199236 -0.185142  0.182492 -0.095135  \n",
      "291  0.589589  0.143251 -0.199236  1.000000  0.096421  0.601466  0.280197  \n",
      "292  0.226189  0.420493 -0.185142  0.096421  1.000000  0.270995  0.161895  \n",
      "293  0.452360  0.310659  0.182492  0.601466  0.270995  1.000000  0.200506  \n",
      "294  0.455738  0.104412 -0.095135  0.280197  0.161895  0.200506  1.000000  \n",
      "\n",
      "[293 rows x 293 columns]\n"
     ]
    }
   ],
   "source": [
    "def compute_user_similarity_matrix(model):\n",
    "\n",
    "    from pyspark.sql import SparkSession\n",
    "    from pyspark.ml.recommendation import ALS\n",
    "    from pyspark.sql import Row\n",
    "    import pandas as pd\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "    # Extract user factors\n",
    "    user_factors = model.userFactors.orderBy('id')\n",
    "\n",
    "    # Convert to Pandas DataFrame\n",
    "    user_factors_pd = user_factors.toPandas()\n",
    "\n",
    "    # Create a matrix of user factors\n",
    "    user_ids = user_factors_pd['id'].values\n",
    "    user_features = pd.DataFrame(user_factors_pd['features'].tolist(), index=user_ids)\n",
    "\n",
    "    # Compute cosine similarity\n",
    "    similarity_matrix = cosine_similarity(user_features)\n",
    "\n",
    "    # Convert the similarity matrix to a DataFrame for easier interpretation\n",
    "    user_similarity_df = pd.DataFrame(similarity_matrix, index=user_ids, columns=user_ids)\n",
    "\n",
    "    print(user_similarity_df)\n",
    "    return user_similarity_df\n",
    "\n",
    "user_similarity_df = compute_user_similarity_matrix(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example how to access the similarity between user with itself for  id 2 \n",
    "user_similarity_df.iloc[2][4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_similarity_df.iloc[292][294]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract similar and opposite users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar users of user with id: 294\n",
      "user id: 85,similarity score: 0.6239896009545439\n",
      "user id: 55,similarity score: 0.6569226503842835\n",
      "user id: 158,similarity score: 0.6771854157354843\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Opposite users of user with id: 294\n",
      "user id: 169,similarity score: -0.8374421864310444\n",
      "user id: 71,similarity score: -0.7876019883753745\n",
      "user id: 214,similarity score: -0.7679490775729902\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "[(158, 0.6771854157354843), (55, 0.6569226503842835), (85, 0.6239896009545439)]\n",
      "[(169, -0.8374421864310444), (71, -0.7876019883753745), (214, -0.7679490775729902)]\n"
     ]
    }
   ],
   "source": [
    "def extract_similar_and_opposite_users(user_similarity_df,interogated_user_id=294):\n",
    "    import numpy as np\n",
    "\n",
    "    #Note1: if you want to check if user ids are good, \n",
    "    #replace [-4:-1] with [-4:] and see if last user has a similarity score of aprox 1\n",
    "\n",
    "    #Note2: -2 and +2 comes from the fact that we use numpy methods for a pandas dataframe, \n",
    "    # dataframe row index starts from 0; column index from 2\n",
    "\n",
    "    user_similarity_scores_df =user_similarity_df.iloc[interogated_user_id-2]\n",
    "    similar_users = []\n",
    "\n",
    "    print(f'Similar users of user with id: {interogated_user_id}')\n",
    "\n",
    "    for id in np.argsort(user_similarity_scores_df)[-4:-1]:\n",
    "        user_id = id+2 #colum indexes start from 2 because lowest user_id value is 2\n",
    "        similarity_score = user_similarity_scores_df[user_id]\n",
    "\n",
    "        similar_users.append((user_id,similarity_score))\n",
    "        try:\n",
    "            print(f'user id: {user_id},similarity score: {similarity_score}')\n",
    "        except:\n",
    "            print(f'index error is {user_id} ')\n",
    "    \n",
    "    #reverse the list so that most similar user recs come first\n",
    "    similar_users.reverse()\n",
    "\n",
    "    print('-'*100)\n",
    "\n",
    "    opposite_users = []\n",
    "\n",
    "    print(f'Opposite users of user with id: {interogated_user_id}')\n",
    "    for id in np.argsort(user_similarity_scores_df)[:3]:\n",
    "        user_id = id+2\n",
    "        similarity_score = user_similarity_scores_df[user_id]\n",
    "        try:\n",
    "        \n",
    "            opposite_users.append((user_id,similarity_score))\n",
    "            print(f'user id: {user_id},similarity score: {similarity_score}')\n",
    "        except:\n",
    "            print(f'index error is {user_id} ')\n",
    "    print('-'*200)\n",
    "    print(similar_users)\n",
    "    print(opposite_users)\n",
    "\n",
    "    return (similar_users,opposite_users)\n",
    "\n",
    "similar_users,opposite_users = extract_similar_and_opposite_users(user_similarity_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract and filter recommendations based on similar and opposite users "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar users flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id = 158\n",
      "similarity_score =0.6771854157354843\n",
      "[{'post_id': 1043, 'prediction': 1.215896725654602}, {'post_id': 344, 'prediction': 1.171457290649414}, {'post_id': 2570, 'prediction': 0.9763970971107483}, {'post_id': 1605, 'prediction': 0.9448734521865845}, {'post_id': 3102, 'prediction': 0.8179556131362915}, {'post_id': 2825, 'prediction': 0.8111118078231812}, {'post_id': 1791, 'prediction': 0.7611003518104553}, {'post_id': 138, 'prediction': 0.7548078894615173}, {'post_id': 2801, 'prediction': 0.7407549619674683}, {'post_id': 1288, 'prediction': 0.7388342618942261}, {'post_id': 2171, 'prediction': 0.7149159908294678}, {'post_id': 2170, 'prediction': 0.7133132219314575}, {'post_id': 1320, 'prediction': 0.6962420344352722}, {'post_id': 2322, 'prediction': 0.6921878457069397}, {'post_id': 1369, 'prediction': 0.6653997302055359}, {'post_id': 1972, 'prediction': 0.6580663919448853}, {'post_id': 427, 'prediction': 0.6328372359275818}, {'post_id': 609, 'prediction': 0.6328372359275818}, {'post_id': 1882, 'prediction': 0.6216064095497131}, {'post_id': 129, 'prediction': 0.6141714453697205}, {'post_id': 1279, 'prediction': 0.606506884098053}, {'post_id': 2277, 'prediction': 0.6042668223381042}, {'post_id': 261, 'prediction': 0.5932521820068359}, {'post_id': 268, 'prediction': 0.5880923271179199}, {'post_id': 2427, 'prediction': 0.5777391195297241}, {'post_id': 1907, 'prediction': 0.5776392221450806}, {'post_id': 1461, 'prediction': 0.5651944875717163}, {'post_id': 1252, 'prediction': 0.5623754262924194}, {'post_id': 2616, 'prediction': 0.5608242154121399}, {'post_id': 407, 'prediction': 0.5606648921966553}]\n",
      "user_id = 55\n",
      "similarity_score =0.6569226503842835\n",
      "[{'post_id': 1972, 'prediction': 0.8568475842475891}, {'post_id': 2546, 'prediction': 0.8386275768280029}, {'post_id': 2793, 'prediction': 0.771060585975647}, {'post_id': 117, 'prediction': 0.7393345236778259}, {'post_id': 1791, 'prediction': 0.707766592502594}, {'post_id': 1909, 'prediction': 0.6780791282653809}, {'post_id': 1971, 'prediction': 0.675527036190033}, {'post_id': 3180, 'prediction': 0.6602310538291931}, {'post_id': 2816, 'prediction': 0.6547964811325073}, {'post_id': 2322, 'prediction': 0.654530942440033}, {'post_id': 1252, 'prediction': 0.6497485041618347}, {'post_id': 1088, 'prediction': 0.645954430103302}, {'post_id': 1443, 'prediction': 0.6279630064964294}, {'post_id': 2963, 'prediction': 0.6242343187332153}, {'post_id': 2801, 'prediction': 0.6227161884307861}, {'post_id': 3137, 'prediction': 0.6223787069320679}, {'post_id': 2925, 'prediction': 0.6176143884658813}, {'post_id': 2446, 'prediction': 0.6151308417320251}, {'post_id': 3275, 'prediction': 0.6061493158340454}, {'post_id': 2493, 'prediction': 0.5926095247268677}, {'post_id': 2130, 'prediction': 0.5920953750610352}, {'post_id': 2427, 'prediction': 0.5872735977172852}, {'post_id': 3661, 'prediction': 0.5841879844665527}, {'post_id': 2118, 'prediction': 0.581824541091919}, {'post_id': 2525, 'prediction': 0.573388934135437}, {'post_id': 3381, 'prediction': 0.566057562828064}, {'post_id': 3102, 'prediction': 0.5646950006484985}, {'post_id': 3232, 'prediction': 0.5627995729446411}, {'post_id': 1279, 'prediction': 0.5602955222129822}, {'post_id': 1067, 'prediction': 0.5391435027122498}]\n",
      "user_id = 85\n",
      "similarity_score =0.6239896009545439\n",
      "[{'post_id': 1320, 'prediction': 1.2251428365707397}, {'post_id': 2382, 'prediction': 0.9592974781990051}, {'post_id': 1972, 'prediction': 0.9100610613822937}, {'post_id': 1093, 'prediction': 0.7925148606300354}, {'post_id': 1288, 'prediction': 0.7756398320198059}, {'post_id': 1279, 'prediction': 0.7567245960235596}, {'post_id': 1194, 'prediction': 0.7433355450630188}, {'post_id': 3159, 'prediction': 0.7402713894844055}, {'post_id': 2322, 'prediction': 0.7387712597846985}, {'post_id': 1791, 'prediction': 0.7146400213241577}, {'post_id': 2860, 'prediction': 0.7092565894126892}, {'post_id': 2043, 'prediction': 0.6999759078025818}, {'post_id': 2883, 'prediction': 0.6982194781303406}, {'post_id': 2070, 'prediction': 0.6932215094566345}, {'post_id': 2816, 'prediction': 0.6864436864852905}, {'post_id': 2946, 'prediction': 0.6349048614501953}, {'post_id': 2494, 'prediction': 0.6276291608810425}, {'post_id': 1394, 'prediction': 0.6170453429222107}, {'post_id': 1449, 'prediction': 0.6094458103179932}, {'post_id': 3139, 'prediction': 0.6049854159355164}, {'post_id': 2121, 'prediction': 0.5979064702987671}, {'post_id': 1429, 'prediction': 0.5858824253082275}, {'post_id': 2829, 'prediction': 0.5826579332351685}, {'post_id': 1398, 'prediction': 0.5819807648658752}, {'post_id': 818, 'prediction': 0.5752015709877014}, {'post_id': 2530, 'prediction': 0.5751898288726807}, {'post_id': 1088, 'prediction': 0.575029730796814}, {'post_id': 2570, 'prediction': 0.5699405074119568}, {'post_id': 2016, 'prediction': 0.5668155550956726}, {'post_id': 1039, 'prediction': 0.5651379823684692}]\n"
     ]
    }
   ],
   "source": [
    "def generate_sim_recs(ratings_file, baseline_users,current_user_already_rated_posts,num_recs = 30,similar=True):\n",
    "    num_users = len(baseline_users)\n",
    "    #print(num_users)\n",
    "    for index in range(num_users):\n",
    "        sim_user_id,similarity_score = baseline_users[index]\n",
    "\n",
    "        print(f'user_id = {sim_user_id}')\n",
    "        print(f'similarity_score ={similarity_score}')\n",
    "\n",
    "        sim_user_recs = generate_matrix_factorization_recs(ratings_file,user_id=sim_user_id,number_recs=num_recs,similar=similar)\n",
    "        current_user_recs = []\n",
    "        for sim_user_rec_struct in sim_user_recs:\n",
    "\n",
    "            if sim_user_rec_struct['post_id'] in current_user_already_rated_posts:\n",
    "                #print('found already rated post')\n",
    "                continue\n",
    "            else:\n",
    "                current_user_rec = {'post_id':sim_user_rec_struct['post_id'],\n",
    "                                    'prediction':sim_user_rec_struct['prediction'] * similarity_score,\n",
    "                                    'baseline_user_id':sim_user_id,\n",
    "                                    'similarity_score': similarity_score,\n",
    "                                    'baseline_user_prediction':sim_user_rec_struct['prediction'] }\n",
    "\n",
    "                #print(f'current user recommendation :{current_user_rec}')\n",
    "\n",
    "                current_user_recs.append(current_user_rec)\n",
    "    return current_user_recs\n",
    "similar_users_recs = generate_sim_recs(ratings_file=ratingsPysparkDf,baseline_users=similar_users,current_user_already_rated_posts=current_user_already_rated_posts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Opposite users flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id = 169\n",
      "similarity_score =-0.8374421864310444\n",
      "[{'post_id': 1791, 'prediction': -0.9602436423301697}, {'post_id': 1320, 'prediction': -0.9123225212097168}, {'post_id': 2925, 'prediction': -0.8931249380111694}, {'post_id': 2382, 'prediction': -0.7914252281188965}, {'post_id': 2546, 'prediction': -0.7765008211135864}, {'post_id': 3102, 'prediction': -0.756777286529541}, {'post_id': 2493, 'prediction': -0.7426306009292603}, {'post_id': 1909, 'prediction': -0.7376296520233154}, {'post_id': 2070, 'prediction': -0.7358139157295227}, {'post_id': 1971, 'prediction': -0.7228209376335144}, {'post_id': 2322, 'prediction': -0.7074626684188843}, {'post_id': 1972, 'prediction': -0.6970853805541992}, {'post_id': 3137, 'prediction': -0.6918445825576782}, {'post_id': 1153, 'prediction': -0.6788827776908875}, {'post_id': 673, 'prediction': -0.6612066626548767}, {'post_id': 1555, 'prediction': -0.6554703116416931}, {'post_id': 1279, 'prediction': -0.6437687277793884}, {'post_id': 1420, 'prediction': -0.6294471025466919}, {'post_id': 2016, 'prediction': -0.624112606048584}, {'post_id': 3722, 'prediction': -0.6013773679733276}, {'post_id': 3535, 'prediction': -0.5980789661407471}, {'post_id': 1043, 'prediction': -0.5885353088378906}, {'post_id': 2959, 'prediction': -0.5877207517623901}, {'post_id': 1091, 'prediction': -0.5716304779052734}, {'post_id': 2816, 'prediction': -0.5609811544418335}, {'post_id': 1355, 'prediction': -0.5419409871101379}, {'post_id': 1935, 'prediction': -0.5394341945648193}, {'post_id': 1443, 'prediction': -0.5363199710845947}, {'post_id': 115, 'prediction': -0.531247615814209}, {'post_id': 1388, 'prediction': -0.531247615814209}]\n",
      "user_id = 71\n",
      "similarity_score =-0.7876019883753745\n",
      "[{'post_id': 2493, 'prediction': -1.4295122623443604}, {'post_id': 1971, 'prediction': -1.1019411087036133}, {'post_id': 1449, 'prediction': -0.9139394760131836}, {'post_id': 1972, 'prediction': -0.9082947373390198}, {'post_id': 1420, 'prediction': -0.8419042825698853}, {'post_id': 1088, 'prediction': -0.8233301639556885}, {'post_id': 1791, 'prediction': -0.7966403961181641}, {'post_id': 1555, 'prediction': -0.794112503528595}, {'post_id': 2382, 'prediction': -0.7919207811355591}, {'post_id': 2016, 'prediction': -0.7780120968818665}, {'post_id': 3722, 'prediction': -0.7484415173530579}, {'post_id': 2816, 'prediction': -0.7451865673065186}, {'post_id': 2070, 'prediction': -0.741645097732544}, {'post_id': 3692, 'prediction': -0.7410989999771118}, {'post_id': 2427, 'prediction': -0.7078998684883118}, {'post_id': 1826, 'prediction': -0.6966065764427185}, {'post_id': 1935, 'prediction': -0.6880252361297607}, {'post_id': 3137, 'prediction': -0.686450183391571}, {'post_id': 1909, 'prediction': -0.6725797653198242}, {'post_id': 2118, 'prediction': -0.6690877079963684}, {'post_id': 1982, 'prediction': -0.6617596745491028}, {'post_id': 3534, 'prediction': -0.6391518712043762}, {'post_id': 2322, 'prediction': -0.6377876996994019}, {'post_id': 1279, 'prediction': -0.6377569437026978}, {'post_id': 2000, 'prediction': -0.6300773620605469}, {'post_id': 2617, 'prediction': -0.6283177137374878}, {'post_id': 117, 'prediction': -0.6274150013923645}, {'post_id': 2400, 'prediction': -0.621827244758606}, {'post_id': 2959, 'prediction': -0.617379367351532}, {'post_id': 3275, 'prediction': -0.6133206486701965}]\n",
      "user_id = 214\n",
      "similarity_score =-0.7679490775729902\n",
      "[{'post_id': 1972, 'prediction': -0.9922295212745667}, {'post_id': 2915, 'prediction': -0.8784832954406738}, {'post_id': 2070, 'prediction': -0.8608787655830383}, {'post_id': 1971, 'prediction': -0.8219816088676453}, {'post_id': 1449, 'prediction': -0.8184393048286438}, {'post_id': 2493, 'prediction': -0.8083405494689941}, {'post_id': 2382, 'prediction': -0.7972537875175476}, {'post_id': 1741, 'prediction': -0.7840114235877991}, {'post_id': 2561, 'prediction': -0.7783206105232239}, {'post_id': 2171, 'prediction': -0.7748632431030273}, {'post_id': 344, 'prediction': -0.7480141520500183}, {'post_id': 2774, 'prediction': -0.7376489639282227}, {'post_id': 2000, 'prediction': -0.7370027303695679}, {'post_id': 2664, 'prediction': -0.7351382374763489}, {'post_id': 1617, 'prediction': -0.7132051587104797}, {'post_id': 1288, 'prediction': -0.705736517906189}, {'post_id': 138, 'prediction': -0.7024606466293335}, {'post_id': 2322, 'prediction': -0.6999479532241821}, {'post_id': 264, 'prediction': -0.6968098878860474}, {'post_id': 1628, 'prediction': -0.683773398399353}, {'post_id': 2801, 'prediction': -0.6742466688156128}, {'post_id': 1356, 'prediction': -0.672607958316803}, {'post_id': 2410, 'prediction': -0.6680595874786377}, {'post_id': 2427, 'prediction': -0.6672758460044861}, {'post_id': 3534, 'prediction': -0.6645417809486389}, {'post_id': 1389, 'prediction': -0.6607559323310852}, {'post_id': 2942, 'prediction': -0.6595859527587891}, {'post_id': 2118, 'prediction': -0.658809244632721}, {'post_id': 927, 'prediction': -0.6582818031311035}, {'post_id': 606, 'prediction': -0.6555145382881165}]\n"
     ]
    }
   ],
   "source": [
    "opposite_users_recs = generate_sim_recs(ratings_file=ratingsPysparkDf,baseline_users=opposite_users,current_user_already_rated_posts=current_user_already_rated_posts,similar=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing on real users logic "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "matrix factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'post_id': 1972, 'prediction': 1.3016436100006104}\n",
      "{'post_id': 2382, 'prediction': 0.5985916506180975, 'baseline_user_id': 85, 'similarity_score': 0.6239896009545439, 'baseline_user_prediction': 0.9592974781990051}\n",
      "{'post_id': 1972, 'prediction': 0.7619817456034932, 'baseline_user_id': 214, 'similarity_score': -0.7679490775729902, 'baseline_user_prediction': -0.9922295212745667}\n",
      "The metric system would be better were it not based on powers of 10\n",
      "https://www.reddit.com//r/changemyview/comments/imgod1/cmv_the_metric_system_would_be_better_were_it_not/\n",
      "Valid input\n",
      "For most people, cast iron skillets aren't worth it\n",
      "https://www.reddit.com//r/changemyview/comments/dg1s3s/cmv_for_most_people_cast_iron_skillets_arent/\n",
      "Valid input\n",
      "Almost all High-school teen drama tv shows would work better if they took pl...\n",
      "https://www.reddit.com//r/changemyview/comments/sizzw5/cmv_almost_all_highschool_teen_drama_tv_shows/\n",
      "Valid input\n",
      "Eugenics is unethical, but not unscientific.\n",
      "https://www.reddit.com//r/changemyview/comments/jx8h71/cmv_eugenics_is_unethical_but_not_unscientific/\n",
      "Valid input\n",
      "Spontaneous Prayer Makes No Sense\n",
      "https://www.reddit.com//r/changemyview/comments/sbncab/cmv_spontaneous_prayer_makes_no_sense/\n",
      "Valid input\n"
     ]
    }
   ],
   "source": [
    "for rec in matrix_factorization_predictions:\n",
    "    print(rec)\n",
    "    break\n",
    "for rec in similar_users_recs:\n",
    "    print(rec)\n",
    "    break\n",
    "for rec in opposite_users_recs:\n",
    "    print(rec)\n",
    "    break\n",
    "\n",
    "def test_matrix_factorization(recs=matrix_factorization_predictions,tolerance_limit=5):\n",
    "    import data_processing\n",
    "    num_rated_posts = 0\n",
    "    matrix_factorization_results = {}\n",
    "    for data in recs:\n",
    "        id = data['post_id']\n",
    "        res =data_processing.get_resource_info(id)\n",
    "        print(res['title'])\n",
    "        print(res['url'])\n",
    "        is_valid = input('Does the url provide enough info for you to understand the basic ideas expressed in this post?(Y/N):')\n",
    "        if is_valid.lower() == 'y':\n",
    "            print(\"Valid input\")\n",
    "            rec_score = float(input('How much did this recommended post make you see things trough a new perspective?:'))\n",
    "            matrix_factorization_results[id]={'user_score': rec_score, 'predicted_score':data['prediction'],'validity':True}\n",
    "            num_rated_posts +=1\n",
    "        else:\n",
    "            matrix_factorization_results[id]={'validity':False, 'predicted_score':data['prediction']}\n",
    "\n",
    "        current_user_already_rated_posts.add(id)\n",
    "        if num_rated_posts == tolerance_limit:\n",
    "            return matrix_factorization_results\n",
    "    return matrix_factorization_results\n",
    "\n",
    "\n",
    "matrix_factorization_results = test_matrix_factorization(matrix_factorization_predictions) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(current_user_already_rated_posts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "similar users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Money needs to get out of politics\n",
      "https://www.reddit.com//r/changemyview/comments/kyl50g/cmv_money_needs_to_get_out_of_politics/\n",
      "Valid input\n",
      "found already recommended post\n",
      "Transexuals are their own thing, not fully male or female.\n",
      "https://www.reddit.com//r/changemyview/comments/bwrexk/cmv_transexuals_are_their_own_thing_not_fully/\n",
      "Valid input\n",
      "Libertarianism is both selfish and poorly thought-out.\n",
      "https://www.reddit.com//r/changemyview/comments/dj6iqf/cmv_libertarianism_is_both_selfish_and_poorly/\n",
      "Valid input\n",
      "found already recommended post\n",
      "The blame for a mass shooting should be placed on the shooter and not on the...\n",
      "https://www.reddit.com//r/changemyview/comments/cm1ex1/cmv_the_blame_for_a_mass_shooting_should_be/\n",
      "Valid input\n",
      "The loan forgiveness bill might help a little, but doesn't seem to be as \"ge...\n",
      "https://www.reddit.com//r/changemyview/comments/x0t0xw/cmv_the_loan_forgiveness_bill_might_help_a_little/\n",
      "Definition of fascism is being used incorrectly. Both right and left can be ...\n",
      "https://www.reddit.com//r/changemyview/comments/t2ru6g/cmv_definition_of_fascism_is_being_used/\n",
      "Valid input\n"
     ]
    }
   ],
   "source": [
    "import data_processing\n",
    "def test_user_similarity_recommendations(baseline_users_recs,tolerance_limit =5):\n",
    "    num_rated_posts = 0\n",
    "    baseline_user_recs_results = {}\n",
    "    for data in baseline_users_recs:\n",
    "        res_id = data['post_id']\n",
    "        if res_id in current_user_already_rated_posts:\n",
    "            print('found already recommended post')\n",
    "            continue\n",
    "        \n",
    "        res = data_processing.get_resource_info(res_id)\n",
    "        baseline_user_id = data['baseline_user_id']\n",
    "        print(res['title'])\n",
    "        print(res['url'])\n",
    "        is_valid = input('Does the url provide enough info for you to understand the basic ideas expressed in this post?(Y/N):')\n",
    "        if is_valid.lower() == 'y':\n",
    "            print(\"Valid input\")\n",
    "            rec_score = float(input('How much did this recommended post make you see things trough a new perspective?:'))\n",
    "            baseline_user_recs_results[baseline_user_id]={'user_score': rec_score, 'rec_info':data,'validity':True}\n",
    "            num_rated_posts +=1\n",
    "        else:\n",
    "            baseline_user_recs_results[baseline_user_id]={'validity':False, 'rec_info':data}\n",
    "\n",
    "        current_user_already_rated_posts.add(res_id)\n",
    "        if num_rated_posts==tolerance_limit:\n",
    "            return baseline_user_recs_results\n",
    "    return baseline_user_recs_results\n",
    "\n",
    "\n",
    "similar_user_recs_results = test_user_similarity_recommendations(similar_users_recs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(current_user_already_rated_posts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Opposite users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found already recommended post\n",
      "major airlines should just quietly raise their fares by $10 and offer a free...\n",
      "https://www.reddit.com//r/changemyview/comments/ttp1ee/cmv_major_airlines_should_just_quietly_raise/\n",
      "Valid input\n",
      "if we're willing to criticize people like George Washington by today's moral...\n",
      "https://www.reddit.com//r/changemyview/comments/jj8bim/cmv_if_were_willing_to_criticize_people_like/\n",
      "Valid input\n",
      "Guns do not protect against tyranny\n",
      "https://www.reddit.com//r/changemyview/comments/eybq7d/cmv_guns_do_not_protect_against_tyranny/\n",
      "Valid input\n",
      "found already recommended post\n",
      "Abolishing the police will us unable to protect people from violence\n",
      "https://www.reddit.com//r/changemyview/comments/gwnw5l/cmv_abolishing_the_police_will_us_unable_to/\n",
      "Valid input\n",
      "Having 7x More Liberal Arts/General Studies Majors than STEM is a Serious Pr...\n",
      "https://www.reddit.com//r/changemyview/comments/nxi37q/cmv_having_7x_more_liberal_artsgeneral_studies/\n",
      "Valid input\n"
     ]
    }
   ],
   "source": [
    "opposite_user_recs_results = test_user_similarity_recommendations(opposite_users_recs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(current_user_already_rated_posts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "saving results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{214: {'user_score': 1.0, 'rec_info': {'post_id': 2561, 'prediction': 0.5977105949073563, 'baseline_user_id': 214, 'similarity_score': -0.7679490775729902, 'baseline_user_prediction': -0.7783206105232239}, 'validity': True}}\n",
      "{85: {'user_score': 1.0, 'rec_info': {'post_id': 2860, 'prediction': 0.44256873620200476, 'baseline_user_id': 85, 'similarity_score': 0.6239896009545439, 'baseline_user_prediction': 0.7092565894126892}, 'validity': True}}\n",
      "{1972: {'user_score': 1.0, 'predicted_score': 1.3016436100006104, 'validity': True}, 1279: {'user_score': 1.0, 'predicted_score': 1.1852648258209229, 'validity': True}, 2816: {'user_score': 1.0, 'predicted_score': 0.9350828528404236, 'validity': True}, 2118: {'user_score': 1.0, 'predicted_score': 0.9242882132530212, 'validity': True}, 2801: {'user_score': 1.0, 'predicted_score': 0.9189030528068542, 'validity': True}}\n",
      "e\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "print(opposite_user_recs_results)\n",
    "print(similar_user_recs_results)\n",
    "print(matrix_factorization_results)\n",
    "print(name)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "RESULTS_FOLDER_LOCATION = \"collaborative_filtering_results\"\n",
    "results_file_location = os.path.join(RESULTS_FOLDER_LOCATION,name+'_collaborative_filtering.json')\n",
    "\n",
    "results_file = open(results_file_location,'w')\n",
    "\n",
    "final_user_result={\n",
    "    'name': name,\n",
    "    'id':user_id,\n",
    "    'matrix_factorization':matrix_factorization_results,\n",
    "    'similar_users':similar_user_recs_results,\n",
    "    'opposite_users':opposite_user_recs_results\n",
    "}\n",
    "json.dump(final_user_result,results_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loading results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'e', 'id': 294, 'matrix_factorization': {'1972': {'user_score': 1.0, 'predicted_score': 1.3016436100006104, 'validity': True}, '1279': {'user_score': 1.0, 'predicted_score': 1.1852648258209229, 'validity': True}, '2816': {'user_score': 1.0, 'predicted_score': 0.9350828528404236, 'validity': True}, '2118': {'user_score': 1.0, 'predicted_score': 0.9242882132530212, 'validity': True}, '2801': {'user_score': 1.0, 'predicted_score': 0.9189030528068542, 'validity': True}}, 'similar_users': {'85': {'user_score': 1.0, 'rec_info': {'post_id': 2860, 'prediction': 0.44256873620200476, 'baseline_user_id': 85, 'similarity_score': 0.6239896009545439, 'baseline_user_prediction': 0.7092565894126892}, 'validity': True}}, 'opposite_users': {'214': {'user_score': 1.0, 'rec_info': {'post_id': 2561, 'prediction': 0.5977105949073563, 'baseline_user_id': 214, 'similarity_score': -0.7679490775729902, 'baseline_user_prediction': -0.7783206105232239}, 'validity': True}}}\n"
     ]
    }
   ],
   "source": [
    "results_file = open(results_file_location,'r')\n",
    "\n",
    "print(json.load(results_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final recommendation flow for collaborative filtering"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
